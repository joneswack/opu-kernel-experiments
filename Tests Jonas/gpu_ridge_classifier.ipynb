{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "import time\n",
    "\n",
    "import random_features\n",
    "from multiple_regression_solver import MultipleRegressionSolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_data, train_labels), (test_data, test_labels) = FashionMNIST()\n",
    "\n",
    "train_data = np.load('../../datasets/export/fashion_mnist/numpy/train_data_fashion_mnist.npy').astype('uint8')\n",
    "test_data = np.load('../../datasets/export/fashion_mnist/numpy/test_data_fashion_mnist.npy').astype('uint8')\n",
    "train_labels = np.load('../../datasets/export/fashion_mnist/numpy/train_targets_fashion_mnist.npy').astype('uint8')\n",
    "test_labels = np.load('../../datasets/export/fashion_mnist/numpy/test_targets_fashion_mnist.npy').astype('uint8')\n",
    "\n",
    "# Convert one-hot to integers\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "D = train_data[0].reshape(-1).shape[0]\n",
    "\n",
    "# Flatten the images\n",
    "train_data = train_data.reshape(-1, D)\n",
    "test_data = test_data.reshape(-1, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binarize(data, threshold):\n",
    "    data_bin = np.where(data>threshold, 1, 0).astype('uint8')\n",
    "    return data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist has values between 0 and 255\n",
    "threshold = 10\n",
    "\n",
    "train_data_bin = threshold_binarize(train_data, threshold)\n",
    "test_data_bin = threshold_binarize(test_data, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin = threshold_binarize(train_data, 10)\n",
    "test_data_bin = threshold_binarize(test_data, 10)\n",
    "# we need to work with flot32 or float64 for some reason.\n",
    "# otherwise numpy freezes\n",
    "all_data = np.vstack([train_data_bin, test_data_bin]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Processing chunk of size: torch.Size([5000, 784])\n",
      "Total time elapsed (seconds): 115.48934745788574\n",
      "Time per chunk (seconds): 8.249239104134697\n"
     ]
    }
   ],
   "source": [
    "data_proj = synthetic_opu.project_big_np_matrix(all_data, out_dim=100000, chunk_size=5000, projection='opu',\n",
    "                          framework='pytorch', dtype=torch.FloatTensor, cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj = data_proj[:len(train_data_bin)]\n",
    "test_proj = data_proj[len(train_data_bin):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression on the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# like one-hot encoding with 0 corresponding to -1\n",
    "label_binarizer = LabelBinarizer(pos_label=1, neg_label=-1)\n",
    "train_labels_bin = label_binarizer.fit_transform(train_labels)\n",
    "test_labels_bin = label_binarizer.fit_transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = MultipleRegressionSolver(train_proj, train_labels_bin, batch_size=128, cuda=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic OPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1K Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(solver.model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.1977643072605133 Accuracy: 82.2\n",
      "Epoch: 1 Loss: 0.24057672917842865 Accuracy: 78.5\n",
      "Epoch: 2 Loss: 0.1988341361284256 Accuracy: 81.1\n",
      "Epoch: 3 Loss: 0.19358235597610474 Accuracy: 82.8\n",
      "Epoch: 4 Loss: 0.17926564812660217 Accuracy: 85.3\n",
      "Epoch: 5 Loss: 0.18776938319206238 Accuracy: 84.3\n",
      "Epoch: 6 Loss: 0.18488942086696625 Accuracy: 83.4\n",
      "Epoch: 7 Loss: 0.184470534324646 Accuracy: 83.7\n",
      "Epoch: 8 Loss: 0.17958873510360718 Accuracy: 80.9\n",
      "Epoch: 9 Loss: 0.16421706974506378 Accuracy: 85.0\n",
      "Epoch: 10 Loss: 0.16249994933605194 Accuracy: 83.5\n",
      "Epoch: 11 Loss: 0.16840437054634094 Accuracy: 83.9\n",
      "Epoch: 12 Loss: 0.17301011085510254 Accuracy: 82.2\n",
      "Epoch: 13 Loss: 0.17343157529830933 Accuracy: 81.9\n",
      "Epoch: 14 Loss: 0.15697996318340302 Accuracy: 84.0\n",
      "Epoch: 15 Loss: 0.14851225912570953 Accuracy: 84.6\n",
      "Epoch: 16 Loss: 0.15340712666511536 Accuracy: 82.8\n",
      "Epoch: 17 Loss: 0.14542700350284576 Accuracy: 83.5\n",
      "Epoch: 18 Loss: 0.14289404451847076 Accuracy: 83.4\n",
      "Epoch: 19 Loss: 0.14925725758075714 Accuracy: 85.3\n",
      "Epoch: 20 Loss: 0.15819697082042694 Accuracy: 85.9\n",
      "Epoch: 21 Loss: 0.1432388722896576 Accuracy: 83.9\n",
      "Epoch: 22 Loss: 0.14540737867355347 Accuracy: 82.6\n",
      "Epoch: 23 Loss: 0.14861562848091125 Accuracy: 82.3\n",
      "Epoch: 24 Loss: 0.13521084189414978 Accuracy: 85.1\n",
      "Epoch: 25 Loss: 0.12648752331733704 Accuracy: 85.2\n",
      "Epoch: 26 Loss: 0.15329931676387787 Accuracy: 83.4\n",
      "Epoch: 27 Loss: 0.12628716230392456 Accuracy: 85.3\n",
      "Epoch: 28 Loss: 0.13795636594295502 Accuracy: 85.3\n",
      "Epoch: 29 Loss: 0.13880909979343414 Accuracy: 83.6\n",
      "Epoch: 30 Loss: 0.13860486447811127 Accuracy: 84.7\n",
      "Epoch: 31 Loss: 0.13130253553390503 Accuracy: 86.6\n",
      "Epoch: 32 Loss: 0.13731758296489716 Accuracy: 83.5\n",
      "Epoch: 33 Loss: 0.14607606828212738 Accuracy: 85.4\n",
      "Epoch: 34 Loss: 0.14479710161685944 Accuracy: 85.8\n",
      "Epoch: 35 Loss: 0.16805411875247955 Accuracy: 86.2\n",
      "Epoch: 36 Loss: 0.15614517033100128 Accuracy: 84.0\n",
      "Epoch: 37 Loss: 0.16582737863063812 Accuracy: 80.5\n",
      "Epoch: 38 Loss: 0.14536428451538086 Accuracy: 83.8\n",
      "Epoch: 39 Loss: 0.1433609277009964 Accuracy: 86.4\n",
      "Epoch: 40 Loss: 0.1345565915107727 Accuracy: 84.0\n",
      "Epoch: 41 Loss: 0.14863541722297668 Accuracy: 86.9\n",
      "Epoch: 42 Loss: 0.19721978902816772 Accuracy: 82.7\n",
      "Epoch: 43 Loss: 0.14244818687438965 Accuracy: 83.9\n",
      "Epoch: 44 Loss: 0.13539916276931763 Accuracy: 85.2\n",
      "Epoch: 45 Loss: 0.13411518931388855 Accuracy: 85.4\n",
      "Epoch: 46 Loss: 0.18160244822502136 Accuracy: 84.0\n",
      "Epoch: 47 Loss: 0.12706097960472107 Accuracy: 85.3\n",
      "Epoch: 48 Loss: 0.1468384563922882 Accuracy: 84.9\n",
      "Epoch: 49 Loss: 0.11170586943626404 Accuracy: 88.1\n"
     ]
    }
   ],
   "source": [
    "coefficients = solver.fit(optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.21666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "85.21666666666667"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.classification_score(test_proj, test_labels_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10K Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(solver.model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 19.49797248840332 Accuracy: 12.5\n",
      "Epoch: 1 Loss: 0.9232721328735352 Accuracy: 53.125\n",
      "Epoch: 2 Loss: 0.6023041605949402 Accuracy: 64.84375\n",
      "Epoch: 3 Loss: 0.4681790769100189 Accuracy: 72.65625\n",
      "Epoch: 4 Loss: 0.4207070469856262 Accuracy: 70.3125\n",
      "Epoch: 5 Loss: 0.35498887300491333 Accuracy: 75.0\n",
      "Epoch: 6 Loss: 0.35204654932022095 Accuracy: 85.9375\n",
      "Epoch: 7 Loss: 0.3081686198711395 Accuracy: 83.59375\n",
      "Epoch: 8 Loss: 0.33145350217819214 Accuracy: 78.90625\n",
      "Epoch: 9 Loss: 0.36751434206962585 Accuracy: 76.5625\n",
      "Epoch: 10 Loss: 0.23600712418556213 Accuracy: 86.71875\n",
      "Epoch: 11 Loss: 0.2516993284225464 Accuracy: 83.59375\n",
      "Epoch: 12 Loss: 0.2738135755062103 Accuracy: 80.46875\n",
      "Epoch: 13 Loss: 0.21624425053596497 Accuracy: 88.28125\n",
      "Epoch: 14 Loss: 0.22382351756095886 Accuracy: 84.375\n",
      "Epoch: 15 Loss: 0.29099106788635254 Accuracy: 80.46875\n",
      "Epoch: 16 Loss: 0.22866110503673553 Accuracy: 86.71875\n",
      "Epoch: 17 Loss: 0.24393053352832794 Accuracy: 79.6875\n",
      "Epoch: 18 Loss: 0.22331933677196503 Accuracy: 85.15625\n",
      "Epoch: 19 Loss: 0.18983852863311768 Accuracy: 83.59375\n",
      "Epoch: 20 Loss: 0.1982002705335617 Accuracy: 83.59375\n",
      "Epoch: 21 Loss: 0.2795400619506836 Accuracy: 85.15625\n",
      "Epoch: 22 Loss: 0.20566721260547638 Accuracy: 87.5\n",
      "Epoch: 23 Loss: 0.19598543643951416 Accuracy: 82.03125\n",
      "Epoch: 24 Loss: 0.16655340790748596 Accuracy: 85.15625\n",
      "Epoch: 25 Loss: 0.20098277926445007 Accuracy: 85.15625\n",
      "Epoch: 26 Loss: 0.1704641878604889 Accuracy: 85.9375\n",
      "Epoch: 27 Loss: 0.14496883749961853 Accuracy: 91.40625\n",
      "Epoch: 28 Loss: 0.18617942929267883 Accuracy: 89.0625\n",
      "Epoch: 29 Loss: 0.16198155283927917 Accuracy: 84.375\n",
      "Epoch: 30 Loss: 0.263420969247818 Accuracy: 85.15625\n",
      "Epoch: 31 Loss: 0.19892948865890503 Accuracy: 86.71875\n",
      "Epoch: 32 Loss: 0.13405656814575195 Accuracy: 93.75\n",
      "Epoch: 33 Loss: 0.3273349404335022 Accuracy: 78.125\n",
      "Epoch: 34 Loss: 0.23401400446891785 Accuracy: 82.8125\n",
      "Epoch: 35 Loss: 0.19593480229377747 Accuracy: 88.28125\n",
      "Epoch: 36 Loss: 0.18072929978370667 Accuracy: 89.0625\n",
      "Epoch: 37 Loss: 0.22714301943778992 Accuracy: 84.375\n",
      "Epoch: 38 Loss: 0.1928097903728485 Accuracy: 82.03125\n",
      "Epoch: 39 Loss: 0.19032275676727295 Accuracy: 85.15625\n",
      "Epoch: 40 Loss: 0.14572066068649292 Accuracy: 88.28125\n",
      "Epoch: 41 Loss: 0.1665055751800537 Accuracy: 83.59375\n",
      "Epoch: 42 Loss: 0.13415609300136566 Accuracy: 91.40625\n",
      "Epoch: 43 Loss: 0.15208664536476135 Accuracy: 85.9375\n",
      "Epoch: 44 Loss: 0.15534988045692444 Accuracy: 84.375\n",
      "Epoch: 45 Loss: 0.1429034173488617 Accuracy: 90.625\n",
      "Epoch: 46 Loss: 0.12471369653940201 Accuracy: 87.5\n",
      "Epoch: 47 Loss: 0.16836681962013245 Accuracy: 84.375\n",
      "Epoch: 48 Loss: 0.16401290893554688 Accuracy: 87.5\n",
      "Epoch: 49 Loss: 0.15143874287605286 Accuracy: 87.5\n"
     ]
    }
   ],
   "source": [
    "coefficients = solver.fit(optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.74666666666667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "88.74666666666667"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.classification_score(test_proj, test_labels_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 100K Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(solver.model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 35.02031326293945 Accuracy: 21.09375\n",
      "Epoch: 1 Loss: 1.1676433086395264 Accuracy: 54.6875\n",
      "Epoch: 2 Loss: 0.6797206401824951 Accuracy: 66.40625\n",
      "Epoch: 3 Loss: 0.5919178128242493 Accuracy: 66.40625\n",
      "Epoch: 4 Loss: 0.5301603078842163 Accuracy: 67.96875\n",
      "Epoch: 5 Loss: 0.4421910345554352 Accuracy: 79.6875\n",
      "Epoch: 6 Loss: 0.4331490397453308 Accuracy: 68.75\n",
      "Epoch: 7 Loss: 0.34248507022857666 Accuracy: 78.125\n",
      "Epoch: 8 Loss: 0.33059290051460266 Accuracy: 74.21875\n",
      "Epoch: 9 Loss: 0.37924784421920776 Accuracy: 74.21875\n",
      "Epoch: 10 Loss: 0.2868381440639496 Accuracy: 81.25\n",
      "Epoch: 11 Loss: 0.2873137593269348 Accuracy: 80.46875\n",
      "Epoch: 12 Loss: 0.2708255350589752 Accuracy: 80.46875\n",
      "Epoch: 13 Loss: 0.3619306683540344 Accuracy: 74.21875\n",
      "Epoch: 14 Loss: 0.2695775032043457 Accuracy: 82.8125\n",
      "Epoch: 15 Loss: 0.36703965067863464 Accuracy: 64.0625\n",
      "Epoch: 16 Loss: 0.25032204389572144 Accuracy: 84.375\n",
      "Epoch: 17 Loss: 0.22382381558418274 Accuracy: 84.375\n",
      "Epoch: 18 Loss: 0.25698143243789673 Accuracy: 82.03125\n",
      "Epoch: 19 Loss: 0.29703855514526367 Accuracy: 80.46875\n",
      "Epoch: 20 Loss: 0.2865685522556305 Accuracy: 83.59375\n",
      "Epoch: 21 Loss: 0.29962748289108276 Accuracy: 86.71875\n",
      "Epoch: 22 Loss: 0.2418598234653473 Accuracy: 81.25\n",
      "Epoch: 23 Loss: 0.23740451037883759 Accuracy: 85.15625\n",
      "Epoch: 24 Loss: 0.24799759685993195 Accuracy: 83.59375\n",
      "Epoch: 25 Loss: 0.21698689460754395 Accuracy: 85.9375\n",
      "Epoch: 26 Loss: 0.2209160327911377 Accuracy: 88.28125\n",
      "Epoch: 27 Loss: 0.22288620471954346 Accuracy: 85.9375\n",
      "Epoch: 28 Loss: 0.1753576099872589 Accuracy: 93.75\n",
      "Epoch: 29 Loss: 0.28975796699523926 Accuracy: 81.25\n",
      "Epoch: 30 Loss: 0.2035006582736969 Accuracy: 90.625\n",
      "Epoch: 31 Loss: 0.159262016415596 Accuracy: 88.28125\n",
      "Epoch: 32 Loss: 0.22953160107135773 Accuracy: 88.28125\n",
      "Epoch: 33 Loss: 0.1768016368150711 Accuracy: 86.71875\n",
      "Epoch: 34 Loss: 0.17492318153381348 Accuracy: 87.5\n",
      "Epoch: 35 Loss: 0.23881983757019043 Accuracy: 88.28125\n",
      "Epoch: 36 Loss: 0.17523375153541565 Accuracy: 89.0625\n",
      "Epoch: 37 Loss: 0.19016648828983307 Accuracy: 88.28125\n",
      "Epoch: 38 Loss: 0.23858149349689484 Accuracy: 79.6875\n",
      "Epoch: 39 Loss: 0.18865284323692322 Accuracy: 90.625\n",
      "Epoch: 40 Loss: 0.22793233394622803 Accuracy: 84.375\n",
      "Epoch: 41 Loss: 0.17270582914352417 Accuracy: 87.5\n",
      "Epoch: 42 Loss: 0.16300222277641296 Accuracy: 92.1875\n",
      "Epoch: 43 Loss: 0.1691119223833084 Accuracy: 90.625\n",
      "Epoch: 44 Loss: 0.18986353278160095 Accuracy: 85.15625\n",
      "Epoch: 45 Loss: 0.17580075562000275 Accuracy: 89.0625\n",
      "Epoch: 46 Loss: 0.1642162948846817 Accuracy: 91.40625\n",
      "Epoch: 47 Loss: 0.14893865585327148 Accuracy: 94.53125\n",
      "Epoch: 48 Loss: 0.24034428596496582 Accuracy: 85.9375\n",
      "Epoch: 49 Loss: 0.19552338123321533 Accuracy: 89.0625\n"
     ]
    }
   ],
   "source": [
    "coefficients = solver.fit(optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "91.075"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.classification_score(test_proj, test_labels_bin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the RBF kernel during regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, feature_layer=None, zero_init=True):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        \n",
    "        self.feature_layer = feature_layer\n",
    "        \n",
    "        if feature_layer is not None:\n",
    "            d_in = feature_layer.output_features\n",
    "        else:\n",
    "            d_in = input_dim\n",
    "        self.layer = nn.Linear(d_in, output_dim, bias=False)\n",
    "        \n",
    "        if zero_init:\n",
    "            torch.nn.init.zeros_(self.layer.weight)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        if self.feature_layer is not None:\n",
    "            output = self.feature_layer.forward(input)\n",
    "        output = self.layer.forward(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch, cuda):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.type(torch.FloatTensor), target.type(torch.FloatTensor)\n",
    "        if cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = torch.nn.functional.mse_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, test_loader, cuda):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.type(torch.FloatTensor), target.type(torch.FloatTensor)\n",
    "            if cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            output = model(data)\n",
    "            test_loss += torch.nn.functional.mse_loss(output, target).item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.argmax(dim=1, keepdim=True)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "    \n",
    "class BasicDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.184674\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.167938\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.124843\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.118487\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.141304\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8194/10000 (82%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.110836\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.107826\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.114720\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.111316\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.126552\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8265/10000 (83%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.122191\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.109020\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.123352\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.143321\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.155508\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8286/10000 (83%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.180575\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.135244\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.131622\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.185635\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.161586\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8378/10000 (84%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.147297\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.176518\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.139655\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.132935\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.163480\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 8433/10000 (84%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.154929\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.145336\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.113118\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.140164\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.142425\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 8496/10000 (85%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.198860\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.097281\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.123444\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.156210\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.149336\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8614/10000 (86%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.142935\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.146127\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.177892\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.141164\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.209331\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8473/10000 (85%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.145206\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.195463\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.116205\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.168087\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.147183\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8302/10000 (83%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.140504\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.171780\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.111560\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.147446\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.159430\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8633/10000 (86%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.129856\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.167614\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.153156\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.163116\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.170603\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8651/10000 (87%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.139665\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.161140\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.154654\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.106708\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.151455\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8657/10000 (87%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.114727\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.107000\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.195983\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.118842\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.109991\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8605/10000 (86%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.117703\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.132439\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.125847\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.162972\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.131387\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 8467/10000 (85%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.166108\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.128678\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.146433\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.124990\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.120454\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8629/10000 (86%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.123478\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.116896\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.098315\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.121096\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.109311\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8659/10000 (87%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.142106\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.188082\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.167745\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.212294\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.167604\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8664/10000 (87%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.115719\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.144297\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.131347\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.113070\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.130605\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8684/10000 (87%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.124996\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.130350\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.132358\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.105352\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.136363\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8654/10000 (87%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.129147\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.112165\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.223193\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.101359\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.104994\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8722/10000 (87%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.102014\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.102458\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.221518\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.110640\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.117533\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 8481/10000 (85%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.178655\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.100978\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.139216\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.110231\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.096251\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8699/10000 (87%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.132786\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.122081\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.127539\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.115435\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.137161\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8603/10000 (86%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.131856\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.136767\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.135828\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.136647\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.129554\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8646/10000 (86%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.147768\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.099155\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.171819\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.144248\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.152137\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8722/10000 (87%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.109825\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.098943\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.127762\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.157791\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.162885\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8696/10000 (87%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.123289\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.126018\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.119414\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.113509\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.087231\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 8625/10000 (86%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.166215\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.113781\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.117629\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.164304\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.119822\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 8584/10000 (86%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.155596\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.104818\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.105905\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.107527\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.136975\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8672/10000 (87%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.120463\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.111701\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.116549\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.112139\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.112367\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8765/10000 (88%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.105630\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.152277\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.155968\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.105639\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.114786\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8696/10000 (87%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.114412\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.115848\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.128364\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.152666\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.109525\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8572/10000 (86%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.123931\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.117515\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.126890\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.149203\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.118363\n",
      "\n",
      "Test set: Average loss: 0.0017, Accuracy: 8550/10000 (86%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.183081\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.158077\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.144217\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.115611\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.128004\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8723/10000 (87%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.097087\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.106656\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.156389\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.130221\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.155536\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 8444/10000 (84%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.179410\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.121753\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.120975\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.133701\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.116901\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8735/10000 (87%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.096984\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.200221\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.107354\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.146497\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.099278\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 8579/10000 (86%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.154441\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.110361\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.139714\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.129723\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.120518\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8595/10000 (86%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.111835\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.100140\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.107350\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.187266\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.133404\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 8600/10000 (86%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.161322\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.102843\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.124791\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.160977\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.148096\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 8615/10000 (86%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.154473\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.111616\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.166637\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.136777\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.101884\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8734/10000 (87%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.095264\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.126491\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.200729\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.139915\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.103945\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8772/10000 (88%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.090371\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.147394\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.108755\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.115155\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.107325\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8627/10000 (86%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.135384\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.119388\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.107333\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.105613\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.127962\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 8742/10000 (87%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.128586\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.099903\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.120530\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.180357\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.146020\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8717/10000 (87%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.105230\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.103364\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.120998\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.123862\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.128101\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8680/10000 (87%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.130741\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.138415\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.133880\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.119576\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.130722\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 8752/10000 (88%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.091311\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.090392\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.141370\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.143224\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.129310\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 8688/10000 (87%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.127629\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.095741\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.149515\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.115276\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.132326\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8672/10000 (87%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.094172\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.160519\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.132559\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.115504\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.111679\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 8694/10000 (87%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = BasicDataset(train_data_bin, train_labels_bin)\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "test_dataset = BasicDataset(test_data_bin, test_labels_bin)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True, num_workers=0)\n",
    "\n",
    "rbf_layer = random_features.RBFModulePyTorch(784, 10000, tunable_kernel=True)\n",
    "model = RegressionModel(784, 10, feature_layer=rbf_layer, zero_init=False).cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for epoch in range(50):\n",
    "    train(model, train_loader, optimizer, epoch, True)\n",
    "    test(model, test_loader, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012755102040816326"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0020, device='cuda:0', grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1./(2*torch.exp(model.feature_layer.log_lengthscales)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
