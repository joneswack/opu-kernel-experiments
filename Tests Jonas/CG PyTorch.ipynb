{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import random as ran\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(object):\n",
    "\n",
    "    def __init__(self, lengthscale=1., variance=1., noise=1.):\n",
    "        super(RBF, self).__init__()\n",
    "        self.lengthscale = lengthscale\n",
    "        self.variance = variance\n",
    "        self.jitter = 1e-9\n",
    "        # self.noise = noise / self.variance + self.jitter# dividing by variance for new strategy\n",
    "        self.noise = noise\n",
    "\n",
    "    def K(self, X1, X2):\n",
    "        \"\"\" GP squared exponential kernel \"\"\"\n",
    "        pairwise_dists = cdist(X1, X2, 'sqeuclidean')\n",
    "        print(type(pairwise_dists[0,0]))\n",
    "        return self.variance*np.exp(-0.5 * pairwise_dists / self.lengthscale ** 2)\n",
    "        # return pairwise_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solve linear system using conjugate gradient\n",
    "Params:\n",
    "    K - Covariance Matrix\n",
    "    Y - Target labels\n",
    "    init - Initial solution\n",
    "    thershold - Termintion criteria\n",
    "\"\"\"\n",
    "def MultiCGGPU(K, Y, init=None, tol=1e-5, atol=1e-9, max_iterations=15000, cuda=False, num_gpus=3):\n",
    "    N = np.shape(K)[0]\n",
    "    if init is None:\n",
    "        init = np.zeros((N,1))\n",
    "\n",
    "    # self.K = K\n",
    "    # self.Y = Y.flatten()\n",
    "\n",
    "\n",
    "    x = init\n",
    "    R = Y - np.dot(K, x) #initialise residual gradient\n",
    "\n",
    "    # Move two kernel splits to 2 GPUs\n",
    "    K = torch.from_numpy(K).type(torch.FloatTensor) #.cuda()\n",
    "    split_size = K.shape[0] // num_gpus\n",
    "    if cuda:\n",
    "        Ks = []\n",
    "        for i in range(num_gpus):\n",
    "            if i < (num_gpus-1):\n",
    "                Ks.append(\n",
    "                    K[i*split_size:(i+1)*split_size].to('cuda:' + str(i))\n",
    "                )\n",
    "            else:\n",
    "                Ks.append(\n",
    "                    K[i*split_size:].to('cuda:' + str(i))\n",
    "                )\n",
    "\n",
    "    iterations = []\n",
    "    solutions = []\n",
    "\n",
    "    for dim in range(Y.shape[1]):\n",
    "        print('Starting CG for dimension {}'.format(dim))\n",
    "        since = time.time()\n",
    "        # get current residual vector\n",
    "        r = R[:, dim][:, None]\n",
    "\n",
    "        p = r\n",
    "\n",
    "        t = 0\n",
    "\n",
    "        x = torch.from_numpy(init).type(torch.FloatTensor) #.cuda()\n",
    "        r = torch.from_numpy(r).type(torch.FloatTensor) #.cuda()\n",
    "        p = torch.from_numpy(p).type(torch.FloatTensor) #.cuda()\n",
    "\n",
    "        if cuda:\n",
    "            x = x.to('cuda:0')\n",
    "            r = r.to('cuda:0')\n",
    "            ps = [p.to('cuda:' + str(i)) for i in range(num_gpus)]\n",
    "\n",
    "        while True:\n",
    "            with torch.no_grad():\n",
    "                # alpha = np.dot(r.T, r) / np.dot(p.T, np.dot(K, p))\n",
    "                Kps = [Ks[i].mm(ps[i]).to('cuda:0') for i in range(num_gpus)]\n",
    "                Kp = torch.cat(Kps, dim=0)\n",
    "                pKp = ps[0].t().mm(Kp)\n",
    "\n",
    "                alpha = r.t().mm(r) / pKp\n",
    "                x = x + alpha*ps[0]\n",
    "                r_prev = r\n",
    "                # r = r - alpha*np.dot(K, p)\n",
    "                r = r - alpha * Kp\n",
    "\n",
    "                # if ((np.dot(r.T,r).flatten() < (threshold*N)) or (t>15000)):\n",
    "                if ((r.t().mm(r).item() <= max(tol*np.linalg.norm(Y[:, dim]), atol*N)) or (t>max_iterations)):\n",
    "                    break\n",
    "                # if ((r.t().mm(r).item() < (threshold*N)) or (t>max_iterations)):\n",
    "                #     break\n",
    "                # beta = np.dot(r.T, r) / np.dot(r_prev.T, r_prev)\n",
    "                beta = r.t().mm(r) / r_prev.t().mm(r_prev)\n",
    "                ps[0] = r + beta*ps[0]\n",
    "\n",
    "                # we need to send the updated p to gpu_i (two vector transfers in total)\n",
    "                ps = [ps[0].to('cuda:' + str(i)) for i in range(num_gpus)]\n",
    "\n",
    "                t = t + 1\n",
    "\n",
    "        print('Iterations needed: {}'.format(t))\n",
    "        print('Time elapsed: {}'.format(time.time() - since))\n",
    "        iterations.append(t)\n",
    "        if cuda:\n",
    "            x = x.cpu()\n",
    "        solutions.append(x.numpy())\n",
    "\n",
    "    return np.hstack(solutions), iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_data, train_labels), (test_data, test_labels) = FashionMNIST()\n",
    "\n",
    "train_data = np.load('../../datasets/export/fashion_mnist/numpy/train_data_fashion_mnist.npy').astype('float32')\n",
    "test_data = np.load('../../datasets/export/fashion_mnist/numpy/test_data_fashion_mnist.npy').astype('float32')\n",
    "train_labels = np.load('../../datasets/export/fashion_mnist/numpy/train_targets_fashion_mnist.npy').astype('float32')\n",
    "test_labels = np.load('../../datasets/export/fashion_mnist/numpy/test_targets_fashion_mnist.npy').astype('float32')\n",
    "\n",
    "train_data = train_data[:60000]\n",
    "train_labels = train_labels[:60000]\n",
    "\n",
    "# Convert one-hot to integers\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "D = train_data[0].reshape(-1).shape[0]\n",
    "N = len(train_data)\n",
    "\n",
    "# Flatten the images\n",
    "train_data = train_data.reshape(-1, D)\n",
    "test_data = test_data.reshape(-1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binarize(data, threshold):\n",
    "    data_bin = np.where(data>threshold, 1, 0)\n",
    "    return data_bin\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "train_data_bin = threshold_binarize(train_data, threshold).astype('float32')\n",
    "test_data_bin = threshold_binarize(test_data, threshold).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_bin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5cce5a64f321>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mactive_pixels_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mactive_pixels_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data_bin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_bin' is not defined"
     ]
    }
   ],
   "source": [
    "active_pixels_train = train_data_bin.sum(axis=1, keepdims=True)\n",
    "active_pixels_test = test_data_bin.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer(pos_label=1, neg_label=-1)\n",
    "train_labels_bin = label_binarizer.fit_transform(train_labels).astype('float32')\n",
    "test_labels_bin = label_binarizer.fit_transform(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = int(np.sqrt(N))\n",
    "# ipHelper = InducingPointsHelper(0)\n",
    "# XmRandom = ipHelper.get_random_inducing_points(train_data_bin,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XmRandom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = RBF(lengthscale=np.sqrt(D/2), variance=1., noise=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitter = 1e-6\n",
    "# K = kernel.K(train_data_bin, train_data_bin) + jitter*np.identity(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5K estimates\n",
    "kernel_var = 0.1789339259732666\n",
    "lengthscale = 7.177267570983543\n",
    "jitter = 0.04144659858222422\n",
    "gamma = 1. / (2*lengthscale**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00970625574163014"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics.pairwise import polynomial_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after grid search\n",
    "\n",
    "gamma = 0.006\n",
    "var = 1.\n",
    "alpha = 0.1\n",
    "\n",
    "# 0.8839 score\n",
    "\n",
    "K = var * rbf_kernel(train_data_bin, Y=train_data_bin, gamma=gamma) + alpha*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opu_kernel(x, y, gamma=1):\n",
    "    kernel = polynomial_kernel(x, Y=y, degree=2, gamma=1, coef0=0)\n",
    "    norm_x_sq = np.linalg.norm(x, ord=2, axis=1, keepdims=True) ** 2\n",
    "    norm_y_sq = np.linalg.norm(y, ord=2, axis=1, keepdims=True) ** 2\n",
    "\n",
    "    # corresponds to element-wise addition of norm_x^2 * norm_y^2\n",
    "    kernel += np.dot(norm_x_sq, norm_y_sq.T)\n",
    "    \n",
    "    kernel *= gamma\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opu_kernel_two(x, y, gamma=1):\n",
    "    poly = polynomial_kernel(x, Y=y, degree=2, gamma=1, coef0=0)\n",
    "    norm_x_sq = np.linalg.norm(x, ord=2, axis=1, keepdims=True) ** 2\n",
    "    norm_y_sq = np.linalg.norm(y, ord=2, axis=1, keepdims=True) ** 2\n",
    "    norm_matrix_sq = np.dot(norm_x_sq, norm_y_sq.T)\n",
    "    \n",
    "    return gamma*(4*norm_matrix_sq**2 + 16*norm_matrix_sq*poly + 4*poly**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose gamma according to the random feature optimization step\n",
    "gamma = 0.001**2 * 784\n",
    "# alpha is chosen like that as well\n",
    "alpha = 10\n",
    "K = opu_kernel(train_data_bin, y=train_data_bin, gamma=gamma) + alpha*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.001**4 * 784\n",
    "alpha = 10\n",
    "K = opu_kernel_two(train_data_bin, y=train_data_bin, gamma=gamma) + alpha*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern = bunch.Bunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern.K = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern.noise = jitter\n",
    "# kern.jitter = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# originally adding noise\n",
    "# K = kernel.K(train_data_bin,train_data_bin) + kernel.noise*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(K[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[267.19116 , 197.69812 , 134.91069 , ..., 125.52937 , 214.44438 ,\n",
       "         71.30087 ],\n",
       "       [197.69812 , 337.4752  , 187.59235 , ..., 181.74216 , 321.19772 ,\n",
       "         69.19427 ],\n",
       "       [134.91069 , 187.59235 , 166.57419 , ..., 134.55635 , 198.69382 ,\n",
       "         47.140347],\n",
       "       ...,\n",
       "       [125.52937 , 181.74216 , 134.55635 , ..., 159.7142  , 193.56255 ,\n",
       "         45.5896  ],\n",
       "       [214.44438 , 321.19772 , 198.69382 , ..., 193.56255 , 386.4768  ,\n",
       "         75.47255 ],\n",
       "       [ 71.30087 ,  69.19427 ,  47.140347, ...,  45.5896  ,  75.47255 ,\n",
       "         54.783646]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(K[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.float32'>\n",
      "Size: (10000, 100) (100, 100)\n"
     ]
    }
   ],
   "source": [
    "# prec = Nystrom(train_data_bin, kern, XmRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prec.precon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv = prec.get_inversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_labels[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1K dimensions: 1 second/label\n",
    "# 10K dimensiosn: 1724 seconds/label (0.5 hours)\n",
    "# in theory: 1000x slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CG for dimension 0\n",
      "Iterations needed: 1525\n",
      "Time elapsed: 26.142972946166992\n",
      "Starting CG for dimension 1\n",
      "Iterations needed: 1392\n",
      "Time elapsed: 23.122112035751343\n",
      "Starting CG for dimension 2\n",
      "Iterations needed: 1546\n",
      "Time elapsed: 25.789490938186646\n",
      "Starting CG for dimension 3\n",
      "Iterations needed: 1535\n",
      "Time elapsed: 25.419824600219727\n",
      "Starting CG for dimension 4\n",
      "Iterations needed: 1528\n",
      "Time elapsed: 25.4859881401062\n",
      "Starting CG for dimension 5\n",
      "Iterations needed: 1447\n",
      "Time elapsed: 23.974270343780518\n",
      "Starting CG for dimension 6\n",
      "Iterations needed: 1565\n",
      "Time elapsed: 25.968250036239624\n",
      "Starting CG for dimension 7\n",
      "Iterations needed: 1503\n",
      "Time elapsed: 24.920526266098022\n",
      "Starting CG for dimension 8\n",
      "Iterations needed: 1453\n",
      "Time elapsed: 24.117175579071045\n",
      "Starting CG for dimension 9\n",
      "Iterations needed: 1434\n",
      "Time elapsed: 23.824496746063232\n",
      "Done. Iterations: [1525, 1392, 1546, 1535, 1528, 1447, 1565, 1503, 1453, 1434]\n",
      "Time: 366.59290409088135\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "# print('Running CG for dim', dim)\n",
    "# pcg = RegularPcgPyTorch(K, train_labels_bin[:, dim][:, None], prec.precon, threshold=1e-9, preconInv=inv)\n",
    "# dual_coef = linalg.solve(K, train_labels_bin, sym_pos=True, overwrite_a=False)\n",
    "dual_coef, iterations = MultiCGGPU(K, train_labels_bin, tol=1e-11, atol=1e-9, max_iterations=10*N, cuda=True, num_gpus=2)\n",
    "# dual_cofs.append(pcg.result)\n",
    "# coef, info = cg(K, train_labels_bin[:, dim], tol=1e-5) # M=inv\n",
    "# coef, info = gmres(K, train_labels_bin[:, dim], tol=1e-5)\n",
    "# dual_cofs.append(coef.reshape((-1, 1)))\n",
    "# print('Info:', info)\n",
    "print('Done. Iterations:', iterations)\n",
    "print('Time:', time.time() - since)\n",
    "    \n",
    "# dual_coef = np.hstack(dual_cofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test = opu_kernel_two(test_data_bin, y=train_data_bin, gamma=gamma)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test = var * rbf_kernel(test_data_bin, train_data_bin, gamma=gamma)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.sum(np.equal(np.argmax(prediction, 1), np.argmax(test_labels_bin, 1))) / len(test_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.53"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPU^2: 60K!\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.02"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPU after gpflow mini-batch optimization\n",
    "# might be overrated because verification was done with test set\n",
    "\n",
    "# m.kern.variance = 0.0018913713117732164\n",
    "# m.likelihood.variance = 5.61412412417899\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.21"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10K\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.55"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPU: 60K!!!\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.51"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test = variance * rbf_kernel(test_data_bin, Y=train_data_bin, gamma=gamma)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.66000000000001"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf sparse parameters (60K inversion successful)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.73"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf after proper grid search\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_features = np.load('conv_features/cifar10/models/vgg16_bn_avgpool.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25088)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_features['test'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF: gamma = 0.00001, alpha = 0.10, scale = 1.0, threshold = 0.4\n",
    "# OPU: alpha = 100.00, degree = 1.0, dummy = 100, scale = 0.00001, threshold = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binarize(data, threshold):\n",
    "    data_bin = np.where(data>threshold, 1, 0)\n",
    "    return data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.4\n",
    "\n",
    "features_train = threshold_binarize(vgg_features['train'], threshold)\n",
    "features_test = threshold_binarize(vgg_features['test'], threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load('conv_features/cifar10/labels.npz')\n",
    "train_labels = labels['train']\n",
    "test_labels = labels['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer(pos_label=1, neg_label=-1)\n",
    "train_labels_bin = label_binarizer.fit_transform(train_labels).astype('float32')\n",
    "test_labels_bin = label_binarizer.fit_transform(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OPU Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def compute_opu_kernel_gpu(data, data_y=None, gamma=1., dtype=torch.FloatTensor, cuda=True):\n",
    "    \n",
    "#     N = len(data)\n",
    "#     n_chunks = math.ceil(N / chunk_size)\n",
    "    \n",
    "#     output_chunks = []\n",
    "    \n",
    "#     for i in range(n_chunks):\n",
    "#         data_chunk = data[i*chunk_size:(i+1)*chunk_size]\n",
    "        \n",
    "#         data_chunk = torch.from_numpy(data_chunk).type(dtype)\n",
    "#         if cuda:\n",
    "#             data_chunk = data_chunk.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        data = torch.from_numpy(data).type(dtype)\n",
    "        \n",
    "        if cuda:\n",
    "            data = data.cuda()\n",
    "            \n",
    "        norm = data.norm(dim=1, keepdim=True)**2\n",
    "            \n",
    "        if data_y is not None:\n",
    "            data_y = torch.from_numpy(data_y).type(dtype)\n",
    "            if cuda:\n",
    "                data_y = data_y.cuda()\n",
    "                \n",
    "            norm_y = data_y.norm(dim=1, keepdim=True)**2\n",
    "        else:\n",
    "            data_y = data\n",
    "            norm_y = norm\n",
    "\n",
    "        # do the matrix multiply in two passes to save memory\n",
    "        kernel_1 = data[:data.shape[0]//2].mm(data_y.t())**2\n",
    "        kernel_1 = kernel_1.cpu().numpy()\n",
    "        \n",
    "        kernel_2 = data[data.shape[0]//2:].mm(data_y.t())**2\n",
    "        kernel_2 = kernel_2.cpu().numpy()\n",
    "        \n",
    "        kernel = np.vstack([kernel_1, kernel_2])\n",
    "        \n",
    "        # do norm matrix in two passes like above\n",
    "        norm_exp_1 = norm[:norm.shape[0]//2].mm(norm_y.t())\n",
    "        norm_exp_1 = norm_exp_1.cpu().numpy()\n",
    "        \n",
    "        norm_exp_2 = norm[norm.shape[0]//2:].mm(norm_y.t())\n",
    "        norm_exp_2 = norm_exp_2.cpu().numpy()\n",
    "        \n",
    "        norm_exp = np.vstack([norm_exp_1, norm_exp_2])\n",
    "        \n",
    "        kernel += norm_exp\n",
    "\n",
    "        return (kernel * gamma)\n",
    "        \n",
    "    \n",
    "    \n",
    "#     K = torch.from_numpy(K).type(torch.FloatTensor) #.cuda()\n",
    "#     split_size = K.shape[0] // num_gpus\n",
    "#     if cuda:\n",
    "#         Ks = []\n",
    "#         for i in range(num_gpus):\n",
    "#             if i < (num_gpus-1):\n",
    "#                 Ks.append(\n",
    "#                     K[i*split_size:(i+1)*split_size].to('cuda:' + str(i))\n",
    "#                 )\n",
    "#             else:\n",
    "#                 Ks.append(\n",
    "#                     K[i*split_size:].to('cuda:' + str(i))\n",
    "#                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def rbf_gpu(data, data_y=None, gamma=1., var=1., dtype=torch.FloatTensor, cuda=True):\n",
    "    data = torch.from_numpy(data).type(dtype)\n",
    "\n",
    "    if cuda:\n",
    "        data = data.cuda()\n",
    "    \n",
    "    if data_y is not None:\n",
    "        data_y = torch.from_numpy(data_y).type(dtype)\n",
    "        if cuda:\n",
    "            data_y = data_y.cuda()\n",
    "    else:\n",
    "        data_y = data\n",
    "    \n",
    "    with torch.no_grad():\n",
    "#         sq_euclidean_1 = F.pairwise_distance(data[:data.shape[0]//2], data_y, 2, 1e-6, True)**2\n",
    "#         sq_euclidean_1 = sq_euclidean_1.cpu().numpy()\n",
    "        \n",
    "#         sq_euclidean_2 = F.pairwise_distance(data[data.shape[0]//2:], data_y, 2, 1e-6, True)**2\n",
    "#         sq_euclidean_2 = sq_euclidean_2.cpu().numpy()\n",
    "        \n",
    "#         pairwise_dists = np.vstack([sq_euclidean_1, sq_euclidean_2])\n",
    "\n",
    "        pairwise_dists = F.pairwise_distance(data, data_y, 2, 1e-6, True)**2\n",
    "        pairwise_dists = pairwise_dists.cpu().numpy()\n",
    "        \n",
    "        return var*np.exp(-gamma * pairwise_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add dummy\n",
    "dummy = 100\n",
    "data = np.vstack([features_train, features_test])\n",
    "data = np.hstack([data, np.ones((data.shape[0], 1)) * dummy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 25089)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPU:\n",
    "# we chose gamma according to the random feature optimization step\n",
    "gamma = 0.00001**2 * data.shape[1] # *d simulates divide by raw_scale (1/d)\n",
    "# alpha is chosen like that as well\n",
    "alpha = 100\n",
    "# alpha = 10\n",
    "K = compute_opu_kernel_gpu(data[:N], gamma=gamma) + alpha*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF:\n",
    "gamma = 0.00001\n",
    "alpha = 0.10\n",
    "var = 1.0**2\n",
    "\n",
    "K = var * rbf_kernel(data[:N], Y=data[:N], gamma=gamma) + alpha*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 50000)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([377.2977 , 262.1834 , 258.50238, ..., 263.7245 , 262.08038,\n",
       "       263.15872], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CG for dimension 0\n",
      "Iterations needed: 148\n",
      "Time elapsed: 1.8161838054656982\n",
      "Starting CG for dimension 1\n",
      "Iterations needed: 145\n",
      "Time elapsed: 1.7687151432037354\n",
      "Starting CG for dimension 2\n",
      "Iterations needed: 146\n",
      "Time elapsed: 1.7736530303955078\n",
      "Starting CG for dimension 3\n",
      "Iterations needed: 142\n",
      "Time elapsed: 1.7402198314666748\n",
      "Starting CG for dimension 4\n",
      "Iterations needed: 141\n",
      "Time elapsed: 1.7209792137145996\n",
      "Starting CG for dimension 5\n",
      "Iterations needed: 143\n",
      "Time elapsed: 1.7327156066894531\n",
      "Starting CG for dimension 6\n",
      "Iterations needed: 144\n",
      "Time elapsed: 1.7738502025604248\n",
      "Starting CG for dimension 7\n",
      "Iterations needed: 144\n",
      "Time elapsed: 1.775909423828125\n",
      "Starting CG for dimension 8\n",
      "Iterations needed: 142\n",
      "Time elapsed: 1.7249560356140137\n",
      "Starting CG for dimension 9\n",
      "Iterations needed: 138\n",
      "Time elapsed: 1.7077176570892334\n",
      "Done. Iterations: [148, 145, 146, 142, 141, 143, 144, 144, 142, 138]\n",
      "Time: 28.658723831176758\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "# print('Running CG for dim', dim)\n",
    "# pcg = RegularPcgPyTorch(K, train_labels_bin[:, dim][:, None], prec.precon, threshold=1e-9, preconInv=inv)\n",
    "# dual_coef = linalg.solve(K, train_labels_bin, sym_pos=True, overwrite_a=False)\n",
    "dual_coef, iterations = MultiCGGPU(K, train_labels_bin, tol=1e-15, atol=1e-15, max_iterations=10*N, cuda=True, num_gpus=2)\n",
    "# dual_cofs.append(pcg.result)\n",
    "# coef, info = cg(K, train_labels_bin[:, dim], tol=1e-5) # M=inv\n",
    "# coef, info = gmres(K, train_labels_bin[:, dim], tol=1e-5)\n",
    "# dual_cofs.append(coef.reshape((-1, 1)))\n",
    "# print('Info:', info)\n",
    "print('Done. Iterations:', iterations)\n",
    "print('Time:', time.time() - since)\n",
    "    \n",
    "# dual_coef = np.hstack(dual_cofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_test = compute_opu_kernel_gpu(data[N:], data[:N], gamma=gamma)\n",
    "# K_test = rbf_gpu(data[N:], data[:N], gamma=gamma, var=var)\n",
    "K_test = var*rbf_kernel(data[N:], data[:N], gamma=gamma)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.sum(np.equal(np.argmax(prediction, 1), np.argmax(test_labels_bin, 1))) / len(features_test) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPU limit for vgg\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87.02"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf limit for vgg\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
