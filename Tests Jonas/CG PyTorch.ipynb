{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import random as ran\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Superclass for classes of Preconditioners.\n",
    "\n",
    "\"\"\"\n",
    "class Preconditioner(object):\n",
    "\n",
    "    def __init__(self, name = \"\"):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InducingPointsHelper(object):\n",
    "\n",
    "\tdef __init__(self, seed):\n",
    "\t\tran.seed(seed)\n",
    "\t\tself.name = \"InducingPointsHelper\"\n",
    "\n",
    "\t\"\"\"\n",
    "\tReturns a random selection of points from the given dataset\n",
    "\t\tX - Dataset\n",
    "\t\tM - Number of points to be selected\n",
    "\t\"\"\"\n",
    "\tdef get_random_inducing_points(self, X, M):\n",
    "\t\trand = ran.sample(range(0, X.shape[0]), M)\n",
    "\t\treturn X[rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(object):\n",
    "\n",
    "    def __init__(self, lengthscale=1., variance=1., noise=1.):\n",
    "        super(RBF, self).__init__()\n",
    "        self.lengthscale = lengthscale\n",
    "        self.variance = variance\n",
    "        self.jitter = 1e-9\n",
    "        # self.noise = noise / self.variance + self.jitter# dividing by variance for new strategy\n",
    "        self.noise = noise\n",
    "\n",
    "    def K(self, X1, X2):\n",
    "        \"\"\" GP squared exponential kernel \"\"\"\n",
    "        pairwise_dists = cdist(X1, X2, 'sqeuclidean')\n",
    "        print(type(pairwise_dists[0,0]))\n",
    "        return self.variance*np.exp(-0.5 * pairwise_dists / self.lengthscale ** 2)\n",
    "        # return pairwise_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solve linear system using conjugate gradient\n",
    "Params:\n",
    "    K - Covariance Matrix\n",
    "    Y - Target labels\n",
    "    init - Initial solution\n",
    "    thershold - Termintion criteria\n",
    "\"\"\"\n",
    "class PlainCG(object):\n",
    "\n",
    "    def __init__(self, K, Y, init=None, threshold=1e-9):\n",
    "        N = np.shape(K)[0]\n",
    "        if init is None:\n",
    "            init = np.zeros((N,1))\n",
    "\n",
    "        self.K = K\n",
    "        self.Y = Y.flatten()\n",
    "\n",
    "        x = init\n",
    "        r = Y - np.dot(K, x) #initialise residual gradient\n",
    "        p = r\n",
    "\n",
    "        t = 0\n",
    "        while True:\n",
    "            alpha = np.dot(r.T, r) / np.dot(p.T, np.dot(K, p))\n",
    "            x = x + alpha*p\n",
    "            r_prev = r\n",
    "            r = r - alpha*np.dot(K, p)\n",
    "\n",
    "            if ((np.dot(r.T,r).flatten() < (threshold*N)) or (t>15000)):\n",
    "                break\n",
    "            beta = np.dot(r.T, r) / np.dot(r_prev.T, r_prev)\n",
    "            p = r + beta*p\n",
    "            t = t + 1\n",
    "\n",
    "        self.iterations = t\n",
    "        self.result = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solve linear system using conjugate gradient\n",
    "Params:\n",
    "    K - Covariance Matrix\n",
    "    Y - Target labels\n",
    "    init - Initial solution\n",
    "    thershold - Termintion criteria\n",
    "\"\"\"\n",
    "def MultiCGGPU(K, Y, init=None, tol=1e-5, atol=1e-9, max_iterations=15000, cuda=False, num_gpus=3):\n",
    "    N = np.shape(K)[0]\n",
    "    if init is None:\n",
    "        init = np.zeros((N,1))\n",
    "\n",
    "    # self.K = K\n",
    "    # self.Y = Y.flatten()\n",
    "\n",
    "\n",
    "    x = init\n",
    "    R = Y - np.dot(K, x) #initialise residual gradient\n",
    "\n",
    "    # Move two kernel splits to 2 GPUs\n",
    "    K = torch.from_numpy(K).type(torch.FloatTensor) #.cuda()\n",
    "    split_size = K.shape[0] // num_gpus\n",
    "    if cuda:\n",
    "        Ks = []\n",
    "        for i in range(num_gpus):\n",
    "            if i < (num_gpus-1):\n",
    "                Ks.append(\n",
    "                    K[i*split_size:(i+1)*split_size].to('cuda:' + str(i))\n",
    "                )\n",
    "            else:\n",
    "                Ks.append(\n",
    "                    K[i*split_size:].to('cuda:' + str(i))\n",
    "                )\n",
    "\n",
    "    iterations = []\n",
    "    solutions = []\n",
    "\n",
    "    for dim in range(Y.shape[1]):\n",
    "        print('Starting CG for dimension {}'.format(dim))\n",
    "        since = time.time()\n",
    "        # get current residual vector\n",
    "        r = R[:, dim][:, None]\n",
    "\n",
    "        p = r\n",
    "\n",
    "        t = 0\n",
    "\n",
    "        x = torch.from_numpy(init).type(torch.FloatTensor) #.cuda()\n",
    "        r = torch.from_numpy(r).type(torch.FloatTensor) #.cuda()\n",
    "        p = torch.from_numpy(p).type(torch.FloatTensor) #.cuda()\n",
    "\n",
    "        if cuda:\n",
    "            x = x.to('cuda:0')\n",
    "            r = r.to('cuda:0')\n",
    "            ps = [p.to('cuda:' + str(i)) for i in range(num_gpus)]\n",
    "\n",
    "        while True:\n",
    "            with torch.no_grad():\n",
    "                # alpha = np.dot(r.T, r) / np.dot(p.T, np.dot(K, p))\n",
    "                Kps = [Ks[i].mm(ps[i]).to('cuda:0') for i in range(num_gpus)]\n",
    "                Kp = torch.cat(Kps, dim=0)\n",
    "                pKp = ps[0].t().mm(Kp)\n",
    "\n",
    "                alpha = r.t().mm(r) / pKp\n",
    "                x = x + alpha*ps[0]\n",
    "                r_prev = r\n",
    "                # r = r - alpha*np.dot(K, p)\n",
    "                r = r - alpha * Kp\n",
    "\n",
    "                # if ((np.dot(r.T,r).flatten() < (threshold*N)) or (t>15000)):\n",
    "                if ((r.t().mm(r).item() <= max(tol*np.linalg.norm(Y[:, dim]), atol*N)) or (t>max_iterations)):\n",
    "                    break\n",
    "                # if ((r.t().mm(r).item() < (threshold*N)) or (t>max_iterations)):\n",
    "                #     break\n",
    "                # beta = np.dot(r.T, r) / np.dot(r_prev.T, r_prev)\n",
    "                beta = r.t().mm(r) / r_prev.t().mm(r_prev)\n",
    "                ps[0] = r + beta*ps[0]\n",
    "\n",
    "                # we need to send the updated p to gpu_i (two vector transfers in total)\n",
    "                ps = [ps[0].to('cuda:' + str(i)) for i in range(num_gpus)]\n",
    "\n",
    "                t = t + 1\n",
    "\n",
    "        print('Iterations needed: {}'.format(t))\n",
    "        print('Time elapsed: {}'.format(time.time() - since))\n",
    "        iterations.append(t)\n",
    "        if cuda:\n",
    "            x = x.cpu()\n",
    "        solutions.append(x.numpy())\n",
    "\n",
    "    return np.hstack(solutions), iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Solve linear system using conjugate gradient\n",
    "Params:\n",
    "    K - Covariance Matrix\n",
    "    Y - Target labels\n",
    "    init - Initial solution\n",
    "    thershold - Termintion criteria\n",
    "\"\"\"\n",
    "class PlainCGGPU(object):\n",
    "\n",
    "    def __init__(self, K, Y, init=None, threshold=1e-9, cuda=False):\n",
    "        N = np.shape(K)[0]\n",
    "        if init is None:\n",
    "            init = np.zeros((N,1))\n",
    "\n",
    "        self.K = K\n",
    "        self.Y = Y.flatten()\n",
    "\n",
    "        x = init\n",
    "        r = Y - np.dot(K, x) #initialise residual gradient\n",
    "        p = r\n",
    "\n",
    "        t = 0\n",
    "        \n",
    "        x = torch.from_numpy(x).type(torch.FloatTensor) #.cuda()\n",
    "        r = torch.from_numpy(r).type(torch.FloatTensor) #.cuda()\n",
    "        p = torch.from_numpy(p).type(torch.FloatTensor) #.cuda()\n",
    "        K = torch.from_numpy(K).type(torch.FloatTensor) #.cuda()\n",
    "        \n",
    "        if cuda:\n",
    "            x = x.cuda()\n",
    "            r = r.cuda()\n",
    "            p = p.cuda()\n",
    "            K = K.cuda()\n",
    "\n",
    "        while True:\n",
    "            with torch.no_grad():\n",
    "                # alpha = np.dot(r.T, r) / np.dot(p.T, np.dot(K, p))\n",
    "                alpha = r.t().mm(r) / p.t().mm(K).mm(p)\n",
    "                x = x + alpha*p\n",
    "                r_prev = r\n",
    "                # r = r - alpha*np.dot(K, p)\n",
    "                r = r - alpha * K.mm(p)\n",
    "\n",
    "                # if ((np.dot(r.T,r).flatten() < (threshold*N)) or (t>15000)):\n",
    "                if ((r.t().mm(r).item() < (threshold*N)) or (t>15000)):\n",
    "                    break\n",
    "                # beta = np.dot(r.T, r) / np.dot(r_prev.T, r_prev)\n",
    "                beta = r.t().mm(r) / r_prev.t().mm(r_prev)\n",
    "                p = r + beta*p\n",
    "                t = t + 1\n",
    "\n",
    "        self.iterations = t\n",
    "        if cuda:\n",
    "            x = x.cpu()\n",
    "        self.result = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cg(object):\n",
    "\n",
    "    def __init__(self, K, Y, init=None, threshold=1e-9, cuda=False):\n",
    "        N = np.shape(K)[0]\n",
    "        if init is None:\n",
    "            init = np.zeros((N,1))\n",
    "\n",
    "        self.K = K\n",
    "        self.Y = Y.flatten()\n",
    "\n",
    "        x = init\n",
    "        r = Y - np.dot(K, x) #initialise residual gradient\n",
    "        p = r\n",
    "        \n",
    "        t = 0\n",
    "        \n",
    "#         x = torch.from_numpy(x).type(torch.FloatTensor) #.cuda()\n",
    "#         r = torch.from_numpy(r).type(torch.FloatTensor) #.cuda()\n",
    "#         p = torch.from_numpy(p).type(torch.FloatTensor) #.cuda()\n",
    "#         K = torch.from_numpy(K).type(torch.FloatTensor) #.cuda()\n",
    "        \n",
    "#         if cuda:\n",
    "#             x = torch.from_numpy(x).cuda()\n",
    "#             r = torch.from_numpy(r).cuda()\n",
    "#             p = torch.from_numpy(p).cuda()\n",
    "#             K = torch.from_numpy(K).cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            while True:\n",
    "                # scalar\n",
    "                # old_resid_norm = r.norm()**2 # r.t().mm(r).item()\n",
    "                old_resid_norm = r.T @ r\n",
    "                # alpha = old_resid_norm / p.t().mm(K).mm(p)\n",
    "                alpha = old_resid_norm / p.T @ K @ p\n",
    "                \n",
    "                # vector\n",
    "                x = x + alpha*p\n",
    "                # r_prev = r\n",
    "                # vector\n",
    "                # r = r - alpha * K.mm(p)\n",
    "                r = r - alpha * K @ p\n",
    "                \n",
    "                #print('Iteration:', t)\n",
    "                #print('Shape r', r.shape)\n",
    "                \n",
    "                # resid_norm = r.norm()**2 # r.t().mm(r).item()\n",
    "                resid_norm = r.T @ r\n",
    "                \n",
    "                break\n",
    "\n",
    "                if (resid_norm < (threshold*N)) or (t>15000):\n",
    "                    break\n",
    "                beta = resid_norm / old_resid_norm\n",
    "                p = r + beta*p\n",
    "                t = t + 1\n",
    "        del K, p, r\n",
    "\n",
    "        self.iterations = t\n",
    "        self.result = x\n",
    "        \n",
    "#         if cuda:\n",
    "#             for i in range(1, 10):\n",
    "#                 try:\n",
    "#                     torch.cuda.empty_cache()\n",
    "#                     self.result = x.cpu().numpy()\n",
    "#                     break\n",
    "#                 except RuntimeError as e:\n",
    "#                     print('Attempt {}. Out of memory. Retrying...'.format(i))\n",
    "#                     print(e)\n",
    "#                     # torch.cuda.empty_cache()\n",
    "#                     time.sleep(i * 2)\n",
    "#         else:\n",
    "#             self.result = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularPcgPyTorch(object):\n",
    "\n",
    "    def __init__(self, K, Y, P, init=None, threshold=1e-9, preconInv=None):\n",
    "        N = np.shape(K)[0]\n",
    "        if init is None:\n",
    "            init = np.zeros((N,1))\n",
    "\n",
    "        if preconInv is None:\n",
    "            preconInv = np.linalg.inv(P)\n",
    "\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.Y = Y.flatten()\n",
    "\n",
    "        x = init\n",
    "        r = Y - np.dot(K, x) #initialise residual gradient\n",
    "        z = np.dot(preconInv, r)\n",
    "        p = z\n",
    "\n",
    "        outerC = 0\n",
    "        \n",
    "        # move data to pytorch / cuda\n",
    "        x = torch.from_numpy(x).type(torch.FloatTensor) #.cuda()\n",
    "        r = torch.from_numpy(r).type(torch.FloatTensor) #.cuda()\n",
    "        z = torch.from_numpy(z).type(torch.FloatTensor) #.cuda()\n",
    "        p = torch.from_numpy(p).type(torch.FloatTensor) #.cuda()\n",
    "        K = torch.from_numpy(K).type(torch.FloatTensor) #.cuda()\n",
    "        preconInv = torch.from_numpy(preconInv).type(torch.FloatTensor) #.cuda()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            while True:\n",
    "                alpha = r.t().mm(z) / p.t().mm(K).mm(p)\n",
    "                x = x + alpha*p\n",
    "                r_prev = r\n",
    "                r = r - alpha*K.mm(p)\n",
    "                # norm(residual) <= max(tol*norm(b), atol) might also be an option\n",
    "                if r.t().mm(r) < threshold*N or outerC>10000:\n",
    "                    break\n",
    "                z_prev = z\n",
    "                z = preconInv.mm(r)\n",
    "                beta = z.t().mm(r) / z_prev.t().mm(r_prev)\n",
    "                p = z + beta*p\n",
    "                outerC = outerC + 1\n",
    "\n",
    "        self.iterations = outerC\n",
    "        self.result = x.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularPcg(object):\n",
    "\n",
    "\tdef __init__(self, K, Y, P, init=None, threshold=1e-9, preconInv=None):\n",
    "\t\tN = np.shape(K)[0]\n",
    "\t\tif init is None:\n",
    "\t\t\tinit = np.zeros((N,1))\n",
    "\n",
    "\t\tif preconInv is None:\n",
    "\t\t\tpreconInv = np.linalg.inv(P)\n",
    "\n",
    "\t\tself.K = K\n",
    "\t\tself.P = P\n",
    "\t\tself.Y = Y.flatten()\n",
    "\n",
    "\t\tx = init\n",
    "\t\tr = Y - np.dot(K, x) #initialise residual gradient\n",
    "\t\tz = np.dot(preconInv, r)\n",
    "\t\tp = z\n",
    "\n",
    "\t\touterC = 0\n",
    "\n",
    "\t\twhile True:\n",
    "\t\t\talpha = np.dot(r.T, z) / np.dot(p.T,np.dot(K, p))\n",
    "\t\t\tx = x + alpha*p\n",
    "\t\t\tr_prev = r\n",
    "\t\t\tr = r - alpha*np.dot(K,p)\n",
    "\t\t\t# norm(residual) <= max(tol*norm(b), atol) might also be an option\n",
    "\t\t\tif (np.dot(r.T, r).flatten() < threshold*N or outerC>10000):\n",
    "\t\t\t\tbreak\n",
    "\t\t\tz_prev = z\n",
    "\t\t\tz = np.dot(preconInv, r)\n",
    "\t\t\tbeta = np.dot(z.T, r) / np.dot(z_prev.T, r_prev)\n",
    "\t\t\tp = z + beta*p\n",
    "\t\t\touterC = outerC + 1\n",
    "\t\t\tif outerC % 10 == 0:\n",
    "\t\t\t\tprint('{} iterations completed.'.format(outerC))\n",
    "\t\t\n",
    "\t\tself.iterations = outerC\n",
    "\t\tself.result = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nystrom Preconditioner\n",
    "\"\"\"\n",
    "class Nystrom(Preconditioner):\n",
    "\n",
    "\t\"\"\"\n",
    "\tConstruct preconditioning matrix\n",
    "\t\tX - Training data\n",
    "\t\tkern - Class of kernel function\n",
    "\t\tXm - Inducing points\n",
    "\t\taddNoise - Flag indicating whether to add likelihood variance to kernel matrix\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, X, kern, Xm, addNoise=True):\n",
    "\t\tsuper(Nystrom, self).__init__(\"Nystrom\")\n",
    "\n",
    "\t\tstart = time.time()\n",
    "\n",
    "\t\tself.kern = kern\n",
    "\t\tself.X = X\n",
    "\t\tN = np.shape(X)[0]\n",
    "\t\tM = np.shape(Xm)[0]\n",
    "\t\tself.M = M\n",
    "\t\tself.N = N\n",
    "\n",
    "\t\tKxm = kern.K(X, Xm)\n",
    "\t\tKm = kern.K(Xm, Xm)\n",
    "\n",
    "\t\tself.Kxm = Kxm\n",
    "\t\tself.Km = Km + 1e-6*np.identity(M) # jitter\n",
    "\t\tself.KmInv = np.linalg.inv(self.Km)\n",
    "        \n",
    "\t\tprint('Type:', type(Kxm[0,0]))\n",
    "\t\tprint('Size:', Kxm.shape, self.KmInv.shape)\n",
    "\n",
    "\t\tif addNoise:\n",
    "\t\t\tself.precon = np.dot(np.dot(Kxm,self.KmInv),Kxm.T) + self.kern.noise*np.identity(N)\n",
    "\t\telse:\n",
    "\t\t\tself.precon = np.dot(np.dot(Kxm,self.KmInv),Kxm.T)\n",
    "\n",
    "\t\tself.duration = time.time() - start\n",
    "\n",
    "\t\"\"\"\n",
    "\tCompute inversion of the preconditioner.\n",
    "\t\"\"\"\n",
    "\tdef get_inversion(self):\n",
    "\t\tN = np.shape(self.X)[0]\n",
    "\t\tM = np.shape(self.Km)[0]\n",
    "\t\tnoise = self.kern.noise\n",
    "\t\tinv_noise = float(1) / noise\n",
    "\t\tnoise_matrix = noise*np.identity(M)\n",
    "\n",
    "\t\teigs, eigv = np.linalg.eig(self.KmInv)\n",
    "\t\tfor i in range(len(eigv)):\n",
    "\t\t\tif (eigs[i] < self.kern.jitter):\n",
    "\t\t\t\teigs[i] = self.kern.jitter\n",
    "\t\t\teigs[i] = np.sqrt(eigs[i])\n",
    "\n",
    "\t\teigsD = np.diag(eigs)\n",
    "\t\tleft = np.dot(self.Kxm, np.dot(eigv, eigsD))\n",
    "\t\tright = np.dot(eigsD, np.dot(eigv.T, self.Kxm.T))\n",
    "\n",
    "\t\treturn inv_noise*self.woodbury_inversion(np.identity(N), left, noise_matrix, right)\n",
    "\n",
    "\t\"\"\"\n",
    "\tImplementation of Woodbury's matrix inversion lemma.\n",
    "\t\"\"\"\n",
    "\tdef woodbury_inversion(self, Ainv, U, Cinv, V):\n",
    "\t\tleft_outer = np.dot(Ainv, U)\n",
    "\t\tright_outer = np.dot(V, Ainv)\n",
    "\t\tinner = np.linalg.inv(Cinv + np.dot(V, np.dot(Ainv, U)))\n",
    "\t\treturn Ainv - np.dot(left_outer, np.dot(inner, right_outer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_data, train_labels), (test_data, test_labels) = FashionMNIST()\n",
    "\n",
    "train_data = np.load('../../datasets/export/fashion_mnist/numpy/train_data_fashion_mnist.npy').astype('float32')\n",
    "test_data = np.load('../../datasets/export/fashion_mnist/numpy/test_data_fashion_mnist.npy').astype('float32')\n",
    "train_labels = np.load('../../datasets/export/fashion_mnist/numpy/train_targets_fashion_mnist.npy').astype('float32')\n",
    "test_labels = np.load('../../datasets/export/fashion_mnist/numpy/test_targets_fashion_mnist.npy').astype('float32')\n",
    "\n",
    "train_data = train_data[:60000]\n",
    "train_labels = train_labels[:60000]\n",
    "\n",
    "# Convert one-hot to integers\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "D = train_data[0].reshape(-1).shape[0]\n",
    "N = len(train_data)\n",
    "\n",
    "# Flatten the images\n",
    "train_data = train_data.reshape(-1, D)\n",
    "test_data = test_data.reshape(-1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binarize(data, threshold):\n",
    "    data_bin = np.where(data>threshold, 1, 0)\n",
    "    return data_bin\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "train_data_bin = threshold_binarize(train_data, threshold).astype('float32')\n",
    "test_data_bin = threshold_binarize(test_data, threshold).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pixels_train = train_data_bin.sum(axis=1, keepdims=True)\n",
    "active_pixels_test = test_data_bin.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer(pos_label=1, neg_label=-1)\n",
    "train_labels_bin = label_binarizer.fit_transform(train_labels).astype('float32')\n",
    "test_labels_bin = label_binarizer.fit_transform(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M = int(np.sqrt(N))\n",
    "# ipHelper = InducingPointsHelper(0)\n",
    "# XmRandom = ipHelper.get_random_inducing_points(train_data_bin,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XmRandom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel = RBF(lengthscale=np.sqrt(D/2), variance=1., noise=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitter = 1e-6\n",
    "# K = kernel.K(train_data_bin, train_data_bin) + jitter*np.identity(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5K estimates\n",
    "kernel_var = 0.1789339259732666\n",
    "lengthscale = 7.177267570983543\n",
    "jitter = 0.04144659858222422\n",
    "gamma = 1. / (2*lengthscale**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00970625574163014"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitter = 1e-6\n",
    "# kernel_var = 100.0\n",
    "K = 1 * rbf_kernel(train_data_bin, Y=train_data_bin, gamma=None) + 1e-6*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.metrics.pairwise import polynomial_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# jitter = 1e-6\n",
    "# kernel_var = 100.0\n",
    "K = kernel_var * rbf_kernel(train_data_bin, Y=train_data_bin, gamma=gamma) + jitter*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opu_kernel(x, y, gamma=1):\n",
    "    kernel = polynomial_kernel(x, Y=y, degree=2, gamma=1, coef0=0)\n",
    "    norm_x_sq = np.linalg.norm(x, ord=2, axis=1, keepdims=True) ** 2\n",
    "    norm_y_sq = np.linalg.norm(y, ord=2, axis=1, keepdims=True) ** 2\n",
    "\n",
    "    # corresponds to element-wise addition of norm_x^2 * norm_y^2\n",
    "    kernel += np.dot(norm_x_sq, norm_y_sq.T)\n",
    "    \n",
    "    kernel *= gamma\n",
    "    \n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.001**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we chose gamma according to the random feature optimization step\n",
    "gamma = 0.001\n",
    "# alpha is chosen like that as well\n",
    "alpha = 10\n",
    "K = opu_kernel(train_data_bin, y=train_data_bin, gamma=gamma) + alpha*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 60000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern = bunch.Bunch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern.K = K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern.noise = jitter\n",
    "# kern.jitter = 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# originally adding noise\n",
    "# K = kernel.K(train_data_bin,train_data_bin) + kernel.noise*np.identity(N).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(K[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-06"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel.noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[338.05    , 252.16599 , 172.07997 , ..., 160.11401 , 273.526   ,\n",
       "         90.945   ],\n",
       "       [252.16599 , 427.698   , 239.27599 , ..., 231.814   , 409.691   ,\n",
       "         88.257996],\n",
       "       [172.07997 , 239.27599 , 209.71199 , ..., 171.628   , 253.436   ,\n",
       "         60.128   ],\n",
       "       ...,\n",
       "       [160.11401 , 231.814   , 171.628   , ..., 200.962   , 246.89102 ,\n",
       "         58.15    ],\n",
       "       [273.526   , 409.691   , 253.436   , ..., 246.89102 , 490.20004 ,\n",
       "         96.266014],\n",
       "       [ 90.945   ,  88.257996,  60.128   , ...,  58.15    ,  96.266014,\n",
       "         67.122   ]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(K[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.float32'>\n",
      "Size: (10000, 100) (100, 100)\n"
     ]
    }
   ],
   "source": [
    "# prec = Nystrom(train_data_bin, kern, XmRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10000)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prec.precon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inv = prec.get_inversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 5000)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_labels[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1K dimensions: 1 second/label\n",
    "# 10K dimensiosn: 1724 seconds/label (0.5 hours)\n",
    "# in theory: 1000x slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_coef = linalg.solve(K, y, sym_pos=True, overwrite_a=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting CG for dimension 0\n",
      "Iterations needed: 749\n",
      "Time elapsed: 13.044814825057983\n",
      "Starting CG for dimension 1\n",
      "Iterations needed: 725\n",
      "Time elapsed: 12.123180150985718\n",
      "Starting CG for dimension 2\n",
      "Iterations needed: 762\n",
      "Time elapsed: 12.656646013259888\n",
      "Starting CG for dimension 3\n",
      "Iterations needed: 739\n",
      "Time elapsed: 12.257280349731445\n",
      "Starting CG for dimension 4\n",
      "Iterations needed: 780\n",
      "Time elapsed: 12.91981053352356\n",
      "Starting CG for dimension 5\n",
      "Iterations needed: 737\n",
      "Time elapsed: 12.25653624534607\n",
      "Starting CG for dimension 6\n",
      "Iterations needed: 772\n",
      "Time elapsed: 12.79292368888855\n",
      "Starting CG for dimension 7\n",
      "Iterations needed: 733\n",
      "Time elapsed: 12.154973983764648\n",
      "Starting CG for dimension 8\n",
      "Iterations needed: 720\n",
      "Time elapsed: 11.930649757385254\n",
      "Starting CG for dimension 9\n",
      "Iterations needed: 734\n",
      "Time elapsed: 12.18154764175415\n",
      "Done. Iterations: [749, 725, 762, 739, 780, 737, 772, 733, 720, 734]\n",
      "Time: 253.08103275299072\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "# print('Running CG for dim', dim)\n",
    "# pcg = RegularPcgPyTorch(K, train_labels_bin[:, dim][:, None], prec.precon, threshold=1e-9, preconInv=inv)\n",
    "# dual_coef = linalg.solve(K, train_labels_bin, sym_pos=True, overwrite_a=False)\n",
    "dual_coef, iterations = MultiCGGPU(K, train_labels_bin, tol=1e-5, atol=1e-9, max_iterations=10*N, cuda=True, num_gpus=2)\n",
    "# dual_cofs.append(pcg.result)\n",
    "# coef, info = cg(K, train_labels_bin[:, dim], tol=1e-5) # M=inv\n",
    "# coef, info = gmres(K, train_labels_bin[:, dim], tol=1e-5)\n",
    "# dual_cofs.append(coef.reshape((-1, 1)))\n",
    "# print('Info:', info)\n",
    "print('Done. Iterations:', iterations)\n",
    "print('Time:', time.time() - since)\n",
    "    \n",
    "# dual_coef = np.hstack(dual_cofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test = opu_kernel(test_data_bin, y=train_data_bin, gamma=gamma)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K_test = kernel_var * rbf_kernel(test_data_bin, train_data_bin)\n",
    "# prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float32"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prediction[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.sum(np.equal(np.argmax(prediction, 1), np.argmax(test_labels_bin, 1))) / len(test_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.21"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10K\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.55"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPU: 60K!!!\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.81"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.81"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test = kernel_var * rbf_kernel(test_data_bin, train_data_bin)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.81"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel_var 1\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.81"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel_var 10\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.98"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kernel_var 100\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
