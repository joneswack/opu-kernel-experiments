{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_OUT = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load original features and scaling coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightonml.datasets import FashionMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_labels), (test_data, test_labels) = FashionMNIST()\n",
    "\n",
    "# train_data = np.load('../datasets/export/fashion_mnist/numpy/train_data_fashion_mnist.npy').astype('uint8')\n",
    "# test_data = np.load('../datasets/export/fashion_mnist/numpy/test_data_fashion_mnist.npy').astype('uint8')\n",
    "# train_labels = np.load('../datasets/export/fashion_mnist/numpy/train_targets_fashion_mnist.npy').astype('uint8')\n",
    "# test_labels = np.load('../datasets/export/fashion_mnist/numpy/test_targets_fashion_mnist.npy').astype('uint8')\n",
    "\n",
    "# Convert one-hot to integers\n",
    "# train_labels = np.argmax(train_labels, axis=1)\n",
    "# test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "D = train_data[0].reshape(-1).shape[0]\n",
    "\n",
    "# Flatten the images\n",
    "train_data = train_data.reshape(-1, D)\n",
    "test_data = test_data.reshape(-1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binarize(data, threshold):\n",
    "    data_bin = np.where(data>threshold, 1, 0).astype('uint8')\n",
    "    return data_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fashion mnist has values between 0 and 255\n",
    "threshold = 10\n",
    "\n",
    "train_data_bin = threshold_binarize(train_data, threshold)\n",
    "test_data_bin = threshold_binarize(test_data, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_pixels_train = train_data_bin.sum(axis=1, keepdims=True)\n",
    "active_pixels_test = test_data_bin.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load synthetic opu features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OPUModuleNumpy(object):\n",
    "    def __init__(self, input_features, output_features, activation=None, bias=False, initial_log_scale='auto', dtype='float32'):\n",
    "        super(OPUModuleNumpy, self).__init__()\n",
    "        \n",
    "        self.real_matrix = np.random.normal(loc=0.0, scale=np.sqrt(0.5), size=(input_features, output_features)).astype(dtype)\n",
    "        self.img_matrix = np.random.normal(loc=0.0, scale=np.sqrt(0.5), size=(input_features, output_features)).astype(dtype)\n",
    "        \n",
    "        if bias:\n",
    "            self.bias = np.random.uniform(low=0.0, high=2 * np.pi, size=(1, output_features))\n",
    "        else:\n",
    "            self.bias = None\n",
    "            \n",
    "        self.activation = activation\n",
    "        \n",
    "        if initial_log_scale == 'auto':\n",
    "            self.log_scale = -0.5 * np.log(input_features)\n",
    "        else:\n",
    "            self.log_scale = initial_log_scale\n",
    "        \n",
    "    def project(self, data, matrix):\n",
    "        return np.dot(data, matrix)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        out_real = self.project(data, self.real_matrix) ** 2\n",
    "        out_img = self.project(data, self.img_matrix) ** 2\n",
    "        \n",
    "        output = (out_real + out_img)\n",
    "        if self.bias is not None:\n",
    "            output += self.bias\n",
    "        if self.activation is not None:\n",
    "            output = self.activation(output)\n",
    "\n",
    "        return np.exp(self.log_scale) * output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opm = OPUModuleNumpy(784, D_OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_projection = opm.forward(np.vstack([train_data_bin, test_data_bin]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Ridge Classifier on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scale = (np_projection / np.vstack([active_pixels_train, active_pixels_test])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03596806274069604"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03571428571428571"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# raw_scale should be 2*0.5 * 1. / sqrt(D_in)\n",
    "1. / np.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha':[0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/alpha/jonas-wacker/opu-venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.05597e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0.8826     0.8826     0.8826     0.88263333]\n",
      "Time per var. 306.11516761779785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/alpha/jonas-wacker/opu-venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.05667e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 [0.88263333 0.88261667 0.88263333 0.88261667]\n",
      "Time per var. 308.7742567062378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/alpha/jonas-wacker/opu-venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=7.43105e-09): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 [0.88265    0.8826     0.88265    0.88331667]\n",
      "Time per var. 309.9567701816559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/alpha/jonas-wacker/opu-venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.07729e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001 [0.88268333 0.8833     0.88495    0.88365   ]\n",
      "Time per var. 311.6124882698059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/alpha/jonas-wacker/opu-venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.07734e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001 [0.88493333 0.88365    0.8721     0.84686667]\n",
      "Time per var. 311.84861516952515\n",
      "1e-05 [0.8721     0.84686667 0.80808333 0.75725   ]\n",
      "Time per var. 307.1119968891144\n"
     ]
    }
   ],
   "source": [
    "for variance in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    since = time.time()\n",
    "    \n",
    "    factor = variance / raw_scale\n",
    "    \n",
    "    model = RidgeClassifier()\n",
    "    clf = GridSearchCV(model, parameters, cv=4, n_jobs=4)\n",
    "    \n",
    "    clf.fit(factor * np_projection[:60000], train_labels)\n",
    "    print(variance, clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    print('Time per var.', time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/alpha/jonas-wacker/opu-venv/lib/python3.5/site-packages/sklearn/linear_model/ridge.py:125: LinAlgWarning: Ill-conditioned matrix (rcond=1.07729e-08): result may not be accurate.\n",
      "  overwrite_a=True).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8815\n"
     ]
    }
   ],
   "source": [
    "# test score\n",
    "variance = 0.001\n",
    "alpha = 10\n",
    "\n",
    "factor = variance / raw_scale\n",
    "\n",
    "clf = RidgeClassifier(alpha=alpha)\n",
    "clf.fit(factor * np_projection[:60000], train_labels)\n",
    "print(clf.score(factor * np_projection[60000:], test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the same for the \"real\" OPU features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "opu_features_train = np.load('fashion_mnist_features_opu/exposure_500/no_dummy/train_100K.npy')[:, :D_OUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "opu_features_test = np.load('fashion_mnist_features_opu/exposure_500/no_dummy/test_100K.npy')[:, :D_OUT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_scale_opu = (np.vstack([opu_features_train, opu_features_test]) / np.vstack([active_pixels_train, active_pixels_test])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11141181042851421"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_scale_opu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0.87886667 0.87886667 0.87886667 0.87886667]\n",
      "Time per var. 484.20058393478394\n",
      "0.1 [0.87886667 0.87886667 0.87886667 0.87881667]\n",
      "Time per var. 482.9742634296417\n",
      "0.01 [0.87886667 0.87881667 0.87911667 0.87963333]\n",
      "Time per var. 483.80264258384705\n",
      "0.001 [0.87911667 0.87963333 0.8807     0.8754    ]\n",
      "Time per var. 480.2423527240753\n",
      "0.0001 [0.8807     0.8754     0.85951667 0.8282    ]\n",
      "Time per var. 489.12343287467957\n",
      "1e-05 [0.85951667 0.8282     0.7855     0.71005   ]\n",
      "Time per var. 484.0654649734497\n"
     ]
    }
   ],
   "source": [
    "for variance in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    since = time.time()\n",
    "    \n",
    "    factor = variance / raw_scale_opu\n",
    "    \n",
    "    model = RidgeClassifier()\n",
    "    clf = GridSearchCV(model, parameters, cv=4, n_jobs=4)\n",
    "    \n",
    "    clf.fit(factor * opu_features_train, train_labels)\n",
    "    print(variance, clf.cv_results_['mean_test_score'])\n",
    "    \n",
    "    print('Time per var.', time.time() - since)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "class RBFModuleNumpy(object):\n",
    "    def __init__(self, input_features, output_features, gamma='auto', dtype='float32'):\n",
    "        super(RBFModuleNumpy, self).__init__()\n",
    "        \n",
    "        if gamma=='auto':\n",
    "            gamma = 1. / input_features\n",
    "        \n",
    "        self.sampler = RBFSampler(gamma=gamma, n_components=output_features, random_state=1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        if not hasattr(self.sampler, 'random_weights_'):\n",
    "            return self.sampler.fit_transform(data)\n",
    "        else:\n",
    "            return self.sampler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0012755102040816326"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'alpha':[0.1, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n",
      "Gamma: 0.001\n",
      "Variance: 1 [0.85918333 0.85918333 0.85918333 0.85918333]\n",
      "Time per var. 12.16813611984253\n",
      "Variance: 0.1 [0.85918333 0.85918333 0.85918333 0.85918333]\n",
      "Time per var. 11.295588731765747\n",
      "Variance: 0.01 [0.85918333 0.85918333 0.85918333 0.85918333]\n",
      "Time per var. 11.923964500427246\n",
      "Variance: 0.001 [0.85918333 0.85918333 0.85918333 0.8592    ]\n",
      "Time per var. 11.163521766662598\n",
      "Variance: 0.0001 [0.85918333 0.8592     0.8592     0.85851667]\n",
      "Time per var. 11.82567048072815\n",
      "Variance: 1e-05 [0.8592     0.85851667 0.85306667 0.83258333]\n",
      "Time per var. 12.034701585769653\n",
      "-----------------------\n",
      "Gamma: 0.002\n",
      "Variance: 1 [0.86108333 0.86108333 0.86108333 0.86108333]\n",
      "Time per var. 11.968480110168457\n",
      "Variance: 0.1 [0.86108333 0.86108333 0.86108333 0.86108333]\n",
      "Time per var. 11.695809125900269\n",
      "Variance: 0.01 [0.86108333 0.86108333 0.86108333 0.86108333]\n",
      "Time per var. 12.141483545303345\n",
      "Variance: 0.001 [0.86108333 0.86108333 0.86108333 0.86108333]\n",
      "Time per var. 11.769330501556396\n",
      "Variance: 0.0001 [0.86108333 0.86108333 0.86108333 0.86105   ]\n",
      "Time per var. 11.702800750732422\n",
      "Variance: 1e-05 [0.86108333 0.86105    0.8608     0.85851667]\n",
      "Time per var. 11.457618713378906\n",
      "-----------------------\n",
      "Gamma: 0.003\n",
      "Variance: 1 [0.86171667 0.86171667 0.86171667 0.86171667]\n",
      "Time per var. 11.658433675765991\n",
      "Variance: 0.1 [0.86171667 0.86171667 0.86171667 0.86171667]\n",
      "Time per var. 11.85697317123413\n",
      "Variance: 0.01 [0.86171667 0.86171667 0.86171667 0.86171667]\n",
      "Time per var. 11.6456880569458\n",
      "Variance: 0.001 [0.86171667 0.86171667 0.86171667 0.86171667]\n",
      "Time per var. 11.38069462776184\n",
      "Variance: 0.0001 [0.86171667 0.86171667 0.86171667 0.86171667]\n",
      "Time per var. 11.562122821807861\n",
      "Variance: 1e-05 [0.86171667 0.86171667 0.86171667 0.86166667]\n",
      "Time per var. 11.209943532943726\n",
      "-----------------------\n",
      "Gamma: 0.004\n",
      "Variance: 1 [0.86175 0.86175 0.86175 0.86175]\n",
      "Time per var. 11.432694911956787\n",
      "Variance: 0.1 [0.86175 0.86175 0.86175 0.86175]\n",
      "Time per var. 11.67415475845337\n",
      "Variance: 0.01 [0.86175 0.86175 0.86175 0.86175]\n",
      "Time per var. 11.436401128768921\n",
      "Variance: 0.001 [0.86175 0.86175 0.86175 0.86175]\n",
      "Time per var. 11.313885688781738\n",
      "Variance: 0.0001 [0.86175    0.86175    0.86175    0.86176667]\n",
      "Time per var. 11.685026407241821\n",
      "Variance: 1e-05 [0.86175    0.86176667 0.86176667 0.86138333]\n",
      "Time per var. 11.745344638824463\n",
      "-----------------------\n",
      "Gamma: 0.005\n",
      "Variance: 1 [0.86255 0.86255 0.86255 0.86255]\n",
      "Time per var. 11.941966772079468\n",
      "Variance: 0.1 [0.86255 0.86255 0.86255 0.86255]\n",
      "Time per var. 11.480597972869873\n",
      "Variance: 0.01 [0.86255 0.86255 0.86255 0.86255]\n",
      "Time per var. 11.679246664047241\n",
      "Variance: 0.001 [0.86255 0.86255 0.86255 0.86255]\n",
      "Time per var. 11.539829015731812\n",
      "Variance: 0.0001 [0.86255    0.86255    0.86256667 0.86256667]\n",
      "Time per var. 11.468081712722778\n",
      "Variance: 1e-05 [0.86256667 0.86256667 0.86245    0.8618    ]\n",
      "Time per var. 12.057320833206177\n",
      "-----------------------\n",
      "Gamma: 0.006\n",
      "Variance: 1 [0.86225 0.86225 0.86225 0.86225]\n",
      "Time per var. 11.92665719985962\n",
      "Variance: 0.1 [0.86225 0.86225 0.86225 0.86225]\n",
      "Time per var. 11.848952293395996\n",
      "Variance: 0.01 [0.86225 0.86225 0.86225 0.86225]\n",
      "Time per var. 11.759045600891113\n",
      "Variance: 0.001 [0.86225 0.86225 0.86225 0.86225]\n",
      "Time per var. 11.74621033668518\n",
      "Variance: 0.0001 [0.86225    0.86225    0.86225    0.86223333]\n",
      "Time per var. 11.82189416885376\n",
      "Variance: 1e-05 [0.86225    0.86223333 0.86208333 0.86176667]\n",
      "Time per var. 11.566447496414185\n",
      "-----------------------\n",
      "Gamma: 0.007\n",
      "Variance: 1 [0.86206667 0.86206667 0.86206667 0.86206667]\n",
      "Time per var. 11.617447137832642\n",
      "Variance: 0.1 [0.86206667 0.86206667 0.86206667 0.86206667]\n",
      "Time per var. 11.712217092514038\n",
      "Variance: 0.01 [0.86206667 0.86206667 0.86206667 0.86206667]\n",
      "Time per var. 11.292552709579468\n",
      "Variance: 0.001 [0.86206667 0.86206667 0.86206667 0.86206667]\n",
      "Time per var. 11.361237287521362\n",
      "Variance: 0.0001 [0.86206667 0.86206667 0.86206667 0.86205   ]\n",
      "Time per var. 11.661955118179321\n",
      "Variance: 1e-05 [0.86206667 0.86205    0.86208333 0.8618    ]\n",
      "Time per var. 11.38692045211792\n",
      "-----------------------\n",
      "Gamma: 0.008\n",
      "Variance: 1 [0.86126667 0.86126667 0.86126667 0.86126667]\n",
      "Time per var. 11.678353548049927\n",
      "Variance: 0.1 [0.86126667 0.86126667 0.86126667 0.86126667]\n",
      "Time per var. 11.23316216468811\n",
      "Variance: 0.01 [0.86126667 0.86126667 0.86126667 0.86126667]\n",
      "Time per var. 11.253663063049316\n",
      "Variance: 0.001 [0.86126667 0.86126667 0.86126667 0.86126667]\n",
      "Time per var. 11.594152688980103\n",
      "Variance: 0.0001 [0.86126667 0.86126667 0.86126667 0.86126667]\n",
      "Time per var. 11.617887258529663\n",
      "Variance: 1e-05 [0.86126667 0.86126667 0.86123333 0.86091667]\n",
      "Time per var. 11.429450273513794\n",
      "-----------------------\n",
      "Gamma: 0.009000000000000001\n",
      "Variance: 1 [0.8605 0.8605 0.8605 0.8605]\n",
      "Time per var. 11.75043797492981\n",
      "Variance: 0.1 [0.8605 0.8605 0.8605 0.8605]\n",
      "Time per var. 11.477277994155884\n",
      "Variance: 0.01 [0.8605 0.8605 0.8605 0.8605]\n",
      "Time per var. 11.127584457397461\n",
      "Variance: 0.001 [0.8605 0.8605 0.8605 0.8605]\n",
      "Time per var. 11.441106081008911\n",
      "Variance: 0.0001 [0.8605 0.8605 0.8605 0.8605]\n",
      "Time per var. 11.388782024383545\n",
      "Variance: 1e-05 [0.8605     0.8605     0.86048333 0.86048333]\n",
      "Time per var. 11.426418542861938\n"
     ]
    }
   ],
   "source": [
    "# for gamma in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "for gamma in np.arange(0.001, 0.01, 0.001):\n",
    "    print('-----------------------')\n",
    "    print('Gamma: {}'.format(gamma))\n",
    "    rbfm = RBFModuleNumpy(784, D_OUT, gamma=gamma)\n",
    "    rbf_projection = rbfm.forward(train_data_bin)\n",
    "    raw_scale_rbf = (rbf_projection / active_pixels_train).mean()\n",
    "    \n",
    "    for variance in [1, 0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "        since = time.time()\n",
    "\n",
    "        factor = variance / raw_scale_rbf\n",
    "\n",
    "        model = RidgeClassifier()\n",
    "        clf = GridSearchCV(model, parameters, cv=4, n_jobs=-1)\n",
    "\n",
    "        clf.fit(factor * rbf_projection, train_labels)\n",
    "        print('Variance: {}'.format(variance),  clf.cv_results_['mean_test_score'])\n",
    "\n",
    "        print('Time per var.', time.time() - since)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gamma: 0.005\n",
    "# Variance: 0.0001 [0.86255    0.86255    0.86256667 0.86256667]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfm = RBFModuleNumpy(784, 10000, gamma=0.005)\n",
    "rbf_projection = rbfm.forward(np.vstack([train_data_bin, test_data_bin]))\n",
    "raw_scale_rbf = (rbf_projection / np.vstack([active_pixels_train, active_pixels_test])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8839\n"
     ]
    }
   ],
   "source": [
    "# test score\n",
    "variance = 0.0001\n",
    "alpha = 10\n",
    "\n",
    "factor = variance / raw_scale_rbf\n",
    "\n",
    "clf = RidgeClassifier(alpha=alpha)\n",
    "clf.fit(factor * rbf_projection[:60000], train_labels)\n",
    "print(clf.score(factor * rbf_projection[60000:], test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (LightOn OPU)",
   "language": "python",
   "name": "lighton_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
