{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import time\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import random as ran\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Superclass for classes of Preconditioners.\n",
    "\n",
    "\"\"\"\n",
    "class Preconditioner(object):\n",
    "\n",
    "    def __init__(self, name = \"\"):\n",
    "        self.name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InducingPointsHelper(object):\n",
    "\n",
    "\tdef __init__(self, seed):\n",
    "\t\tran.seed(seed)\n",
    "\t\tself.name = \"InducingPointsHelper\"\n",
    "\n",
    "\t\"\"\"\n",
    "\tReturns a random selection of points from the given dataset\n",
    "\t\tX - Dataset\n",
    "\t\tM - Number of points to be selected\n",
    "\t\"\"\"\n",
    "\tdef get_random_inducing_points(self, X, M):\n",
    "\t\trand = ran.sample(range(0, X.shape[0]), M)\n",
    "\t\treturn X[rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RBF(object):\n",
    "\n",
    "    def __init__(self, lengthscale=1., variance=1., noise=1.):\n",
    "        super(RBF, self).__init__()\n",
    "        self.lengthscale = lengthscale\n",
    "        self.variance = variance\n",
    "        self.jitter = 1e-9\n",
    "        self.noise = noise / self.variance + self.jitter# dividing by variance for new strategy\n",
    "\n",
    "    def K(self, X1, X2):\n",
    "        \"\"\" GP squared exponential kernel \"\"\"\n",
    "        pairwise_dists = cdist(X1, X2, 'euclidean')\n",
    "        return self.variance*np.exp(-0.5 * (pairwise_dists ** 2) / self.lengthscale ** 2)\n",
    "        # return pairwise_dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularPcgPyTorch(object):\n",
    "\n",
    "    def __init__(self, K, Y, P, init=None, threshold=1e-9, preconInv=None):\n",
    "        N = np.shape(K)[0]\n",
    "        if init is None:\n",
    "            init = np.zeros((N,1))\n",
    "\n",
    "        if preconInv is None:\n",
    "            preconInv = np.linalg.inv(P)\n",
    "\n",
    "        self.K = K\n",
    "        self.P = P\n",
    "        self.Y = Y.flatten()\n",
    "\n",
    "        x = init\n",
    "        r = Y - np.dot(K, x) #initialise residual gradient\n",
    "        z = np.dot(preconInv, r)\n",
    "        p = z\n",
    "\n",
    "        outerC = 0\n",
    "        \n",
    "        # move data to pytorch / cuda\n",
    "        x = torch.from_numpy(x)\n",
    "        r = torch.from_numpy(r)\n",
    "        z = torch.from_numpy(z)\n",
    "        p = torch.from_numpy(p)\n",
    "        K = torch.from_numpy(K)\n",
    "        preconInv = torch.from_numpy(preconInv)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "\n",
    "            while True:\n",
    "                alpha = r.t().mm(z) / p.t().mm(K).mm(p)\n",
    "                x = x + alpha*p\n",
    "                r_prev = r\n",
    "                r = r - alpha*K.mm(p)\n",
    "                # norm(residual) <= max(tol*norm(b), atol) might also be an option\n",
    "                if r.t().mm(r) < threshold*N or outerC>10000:\n",
    "                    break\n",
    "                z_prev = z\n",
    "                z = preconInv.mm(r)\n",
    "                beta = z.t().mm(r) / z_prev.t().mm(r_prev)\n",
    "                p = z + beta*p\n",
    "                outerC = outerC + 1\n",
    "\n",
    "        self.iterations = outerC\n",
    "        self.result = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularPcg(object):\n",
    "\n",
    "\tdef __init__(self, K, Y, P, init=None, threshold=1e-9, preconInv=None):\n",
    "\t\tN = np.shape(K)[0]\n",
    "\t\tif init is None:\n",
    "\t\t\tinit = np.zeros((N,1))\n",
    "\n",
    "\t\tif preconInv is None:\n",
    "\t\t\tpreconInv = np.linalg.inv(P)\n",
    "\n",
    "\t\tself.K = K\n",
    "\t\tself.P = P\n",
    "\t\tself.Y = Y.flatten()\n",
    "\n",
    "\t\tx = init\n",
    "\t\tr = Y - np.dot(K, x) #initialise residual gradient\n",
    "\t\tz = np.dot(preconInv, r)\n",
    "\t\tp = z\n",
    "\n",
    "\t\touterC = 0\n",
    "\n",
    "\t\twhile True:\n",
    "\t\t\talpha = np.dot(r.T, z) / np.dot(p.T,np.dot(K, p))\n",
    "\t\t\tx = x + alpha*p\n",
    "\t\t\tr_prev = r\n",
    "\t\t\tr = r - alpha*np.dot(K,p)\n",
    "\t\t\t# norm(residual) <= max(tol*norm(b), atol) might also be an option\n",
    "\t\t\tif (np.dot(r.T, r).flatten() < threshold*N or outerC>10000):\n",
    "\t\t\t\tbreak\n",
    "\t\t\tz_prev = z\n",
    "\t\t\tz = np.dot(preconInv, r)\n",
    "\t\t\tbeta = np.dot(z.T, r) / np.dot(z_prev.T, r_prev)\n",
    "\t\t\tp = z + beta*p\n",
    "\t\t\touterC = outerC + 1\n",
    "\t\t\n",
    "\t\tself.iterations = outerC\n",
    "\t\tself.result = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Nystrom Preconditioner\n",
    "\"\"\"\n",
    "class Nystrom(Preconditioner):\n",
    "\n",
    "\t\"\"\"\n",
    "\tConstruct preconditioning matrix\n",
    "\t\tX - Training data\n",
    "\t\tkern - Class of kernel function\n",
    "\t\tXm - Inducing points\n",
    "\t\taddNoise - Flag indicating whether to add likelihood variance to kernel matrix\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, X, kern, Xm, addNoise=True):\n",
    "\t\tsuper(Nystrom, self).__init__(\"Nystrom\")\n",
    "\n",
    "\t\tstart = time.time()\n",
    "\n",
    "\t\tself.kern = kern\n",
    "\t\tself.X = X\n",
    "\t\tN = np.shape(X)[0]\n",
    "\t\tM = np.shape(Xm)[0]\n",
    "\t\tself.M = M\n",
    "\t\tself.N = N\n",
    "\n",
    "\t\tKxm = kern.K(X, Xm)\n",
    "\t\tKm = kern.K(Xm, Xm)\n",
    "\n",
    "\t\tself.Kxm = Kxm\n",
    "\t\tself.Km = Km + 1e-6*np.identity(M) # jitter\n",
    "\t\tself.KmInv = np.linalg.inv(self.Km)\n",
    "        \n",
    "\t\tprint('Type:', type(Kxm[0,0]))\n",
    "\t\tprint('Size:', Kxm.shape, self.KmInv.shape)\n",
    "\n",
    "\t\tif addNoise:\n",
    "\t\t\tself.precon = np.dot(np.dot(Kxm,self.KmInv),Kxm.T) + self.kern.noise*np.identity(N)\n",
    "\t\telse:\n",
    "\t\t\tself.precon = np.dot(np.dot(Kxm,self.KmInv),Kxm.T)\n",
    "\n",
    "\t\tself.duration = time.time() - start\n",
    "\n",
    "\t\"\"\"\n",
    "\tCompute inversion of the preconditioner.\n",
    "\t\"\"\"\n",
    "\tdef get_inversion(self):\n",
    "\t\tN = np.shape(self.X)[0]\n",
    "\t\tM = np.shape(self.Km)[0]\n",
    "\t\tnoise = self.kern.noise\n",
    "\t\tinv_noise = float(1) / noise\n",
    "\t\tnoise_matrix = noise*np.identity(M)\n",
    "\n",
    "\t\teigs, eigv = np.linalg.eig(self.KmInv)\n",
    "\t\tfor i in range(len(eigv)):\n",
    "\t\t\tif (eigs[i] < self.kern.jitter):\n",
    "\t\t\t\teigs[i] = self.kern.jitter\n",
    "\t\t\teigs[i] = np.sqrt(eigs[i])\n",
    "\n",
    "\t\teigsD = np.diag(eigs)\n",
    "\t\tleft = np.dot(self.Kxm, np.dot(eigv, eigsD))\n",
    "\t\tright = np.dot(eigsD, np.dot(eigv.T, self.Kxm.T))\n",
    "\n",
    "\t\treturn inv_noise*self.woodbury_inversion(np.identity(N), left, noise_matrix, right)\n",
    "\n",
    "\t\"\"\"\n",
    "\tImplementation of Woodbury's matrix inversion lemma.\n",
    "\t\"\"\"\n",
    "\tdef woodbury_inversion(self, Ainv, U, Cinv, V):\n",
    "\t\tleft_outer = np.dot(Ainv, U)\n",
    "\t\tright_outer = np.dot(V, Ainv)\n",
    "\t\tinner = np.linalg.inv(Cinv + np.dot(V, np.dot(Ainv, U)))\n",
    "\t\treturn Ainv - np.dot(left_outer, np.dot(inner, right_outer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (train_data, train_labels), (test_data, test_labels) = FashionMNIST()\n",
    "\n",
    "train_data = np.load('../datasets/export/fashion_mnist/numpy/train_data_fashion_mnist.npy').astype('float32')\n",
    "test_data = np.load('../datasets/export/fashion_mnist/numpy/test_data_fashion_mnist.npy').astype('float32')\n",
    "train_labels = np.load('../datasets/export/fashion_mnist/numpy/train_targets_fashion_mnist.npy').astype('float32')\n",
    "test_labels = np.load('../datasets/export/fashion_mnist/numpy/test_targets_fashion_mnist.npy').astype('float32')\n",
    "\n",
    "train_data = train_data[:1000]\n",
    "train_labels = train_labels[:1000]\n",
    "\n",
    "# Convert one-hot to integers\n",
    "train_labels = np.argmax(train_labels, axis=1)\n",
    "test_labels = np.argmax(test_labels, axis=1)\n",
    "\n",
    "D = train_data[0].reshape(-1).shape[0]\n",
    "N = len(train_data)\n",
    "\n",
    "# Flatten the images\n",
    "train_data = train_data.reshape(-1, D)\n",
    "test_data = test_data.reshape(-1, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_binarize(data, threshold):\n",
    "    data_bin = np.where(data>threshold, 1, 0)\n",
    "    return data_bin\n",
    "\n",
    "threshold = 10\n",
    "\n",
    "train_data_bin = threshold_binarize(train_data, threshold).astype('float32')\n",
    "test_data_bin = threshold_binarize(test_data, threshold).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_binarizer = LabelBinarizer(pos_label=1, neg_label=-1)\n",
    "train_labels_bin = label_binarizer.fit_transform(train_labels).astype('float32')\n",
    "test_labels_bin = label_binarizer.fit_transform(test_labels).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = int(np.sqrt(N))\n",
    "ipHelper = InducingPointsHelper(0)\n",
    "XmRandom = ipHelper.get_random_inducing_points(train_data,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XmRandom.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = RBF(lengthscale=np.sqrt(D/2), variance=1., noise=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# originally adding noise\n",
    "K = kernel.K(train_data_bin,train_data_bin) + kernel.jitter*np.identity(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.64482552, 0.68118008, ..., 0.67771352, 0.91575153,\n",
       "        0.76209529],\n",
       "       [0.64482552, 1.        , 0.81852192, ..., 0.79587246, 0.63422142,\n",
       "        0.64895107],\n",
       "       [0.68118008, 0.81852192, 1.        , ..., 0.89382533, 0.66487032,\n",
       "        0.64812385],\n",
       "       ...,\n",
       "       [0.67771352, 0.79587246, 0.89382533, ..., 1.        , 0.66148676,\n",
       "        0.63990947],\n",
       "       [0.91575153, 0.63422142, 0.66487032, ..., 0.66148676, 1.        ,\n",
       "        0.76697113],\n",
       "       [0.76209529, 0.64895107, 0.64812385, ..., 0.63990947, 0.76697113,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <class 'numpy.float64'>\n",
      "Size: (1000, 31) (31, 31)\n"
     ]
    }
   ],
   "source": [
    "prec = Nystrom(train_data, kernel, XmRandom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec.precon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv = prec.get_inversion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:, None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "?? cg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running CG for dim 0\n",
      "Done. Iterations: 368\n",
      "Time: 0.7589826583862305\n",
      "Running CG for dim 1\n",
      "Done. Iterations: 371\n",
      "Time: 0.7356622219085693\n",
      "Running CG for dim 2\n",
      "Done. Iterations: 380\n",
      "Time: 0.7248811721801758\n",
      "Running CG for dim 3\n",
      "Done. Iterations: 369\n",
      "Time: 0.7232060432434082\n",
      "Running CG for dim 4\n",
      "Done. Iterations: 380\n",
      "Time: 0.8736495971679688\n",
      "Running CG for dim 5\n",
      "Done. Iterations: 319\n",
      "Time: 0.6026642322540283\n",
      "Running CG for dim 6\n",
      "Done. Iterations: 389\n",
      "Time: 0.7373867034912109\n",
      "Running CG for dim 7\n",
      "Done. Iterations: 321\n",
      "Time: 0.6077091693878174\n",
      "Running CG for dim 8\n",
      "Done. Iterations: 333\n",
      "Time: 0.8163228034973145\n",
      "Running CG for dim 9\n",
      "Done. Iterations: 327\n",
      "Time: 0.6170711517333984\n"
     ]
    }
   ],
   "source": [
    "dual_cofs = []\n",
    "for dim in range(train_labels_bin.shape[1]):\n",
    "    since = time.time()\n",
    "    print('Running CG for dim', dim)\n",
    "    pcg = RegularPcgPyTorch(K, train_labels_bin[:, dim][:, None], prec.precon, threshold=1e-9, preconInv=inv)\n",
    "    dual_cofs.append(pcg.result)\n",
    "    # coef, info = cg(K, train_labels_bin[:, dim], tol=1e-5, M=inv) # M=inv\n",
    "    # dual_cofs.append(coef.reshape((-1, 1)))\n",
    "    # print('Info:', info)\n",
    "    print('Done. Iterations:', pcg.iterations)\n",
    "    print('Time:', time.time() - since)\n",
    "    \n",
    "dual_coef = np.hstack(dual_cofs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dual_coef.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_test = kernel.K(test_data_bin, train_data_bin)\n",
    "prediction = np.dot(K_test, dual_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.sum(np.equal(np.argmax(prediction, 1), np.argmax(test_labels_bin, 1))) / len(test_data) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.02"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.01"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
